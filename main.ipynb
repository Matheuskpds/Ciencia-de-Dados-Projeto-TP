{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_13836\\3409896799.py:9: DtypeWarning: Columns (11,12,17,18,20,21,22,23,25,26,27,28,29,30,31,32,33,36,37,39,40,42,43,44,45,46,47,48,49,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('dados/SpSafe_2022.csv', delimiter=';')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import math\n",
    "import geopandas as gpd\n",
    "import re\n",
    "import numpy as np\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "df = pd.read_csv('dados/SpSafe_2022.csv', delimiter=';')\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">\n",
    "  Códigos criados para localizar as cidades dos dados via latitude e longitude\n",
    "</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<strong>Diferente da primeira entrega, usamos o geopanda para mapear as cidades via latitude e longitude usando shapefile da Fundação Seade (Sistema Estadual de Análise de Dados)</strong>\n",
    "<br>\n",
    "<a href=\"https://portalgeo.seade.gov.br/\">Clique aqui para visitar o site</a>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "malha = gpd.read_file(\"dados/Shapefile/LimiteMunicipal.shp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p> Percorremos cada linha, cruzando os dados do dataframe SpSafe com o que foi gerado com o shapefile da base geográfica dos municípios de São Paulo </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contador_erro = 0\n",
    "for indice, linha in df.iloc[1:].iterrows():\n",
    "\tif pd.isna(linha[\"LATITUDE\"]) and pd.isna(linha[\"LONGITUDE\"]):\n",
    "\t\tcontinue\n",
    "\tif pd.isna(linha[\"CIDADE\"]) and pd.notna(linha[\"LATITUDE\"]) and pd.notna(linha[\"LONGITUDE\"]):\n",
    "\t\tponto = Point(linha[\"LONGITUDE\"], linha[\"LATITUDE\"])\n",
    "\t\tcidade = malha[malha.geometry.contains(ponto)]\n",
    "\t\tif not cidade.empty:\n",
    "\t\t\tdf.at[indice, \"CIDADE\"] = cidade.iloc[0][\"Municipio\"]\n",
    "\t\telse:\n",
    "\t\t\tcontador_erro = contador_erro + 1\n",
    "\t\t\tdf.iloc[indice, \"LATITUDE\", \"LONGITUDE\"]\n",
    "\tif(contador_erro >= 10 and contador_erro % 10 == 0):\n",
    "\t\tprint(f\"{contador_erro} erros.\")\n",
    "\n",
    "df.to_csv('dados/SpSafe_2022.csv', index=False, sep=';', encoding='utf-8')\n",
    "print(\"Gravado\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<h2> Tratamentos de erros</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p> Erros por latitude com virgula em posição incorreta </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_filtrado = df.loc[(\n",
    "    df[\"CIDADE\"].isnull() &\n",
    "    df[\"LATITUDE\"].notnull() &\n",
    "    df[\"LONGITUDE\"].notnull()\n",
    "), [\"NUM_BO\",\"CIDADE\", \"LATITUDE\", \"LONGITUDE\", \"LOGRADOURO\", \"BAIRRO\"]\n",
    "]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foram feitas 13016 alteraçoes\n"
     ]
    }
   ],
   "source": [
    "def verificaMag(valor):\n",
    "    if valor == 0:\n",
    "        return 0\n",
    "    return math.floor(math.log10(abs(valor))) - 1\n",
    "\n",
    "cont_alteracoes = 0\n",
    "\n",
    "for indice, linha in df.iloc[1:].iterrows():\n",
    "    if(pd.isna(linha[\"CIDADE\"]) and pd.notna(linha[\"LATITUDE\"]) and pd.notna(linha[\"LONGITUDE\"])):\n",
    "        lat = linha[\"LATITUDE\"] / 10 ** verificaMag(linha[\"LATITUDE\"])\n",
    "        long = linha[\"LONGITUDE\"] / 10 ** verificaMag(linha[\"LONGITUDE\"])\n",
    "        ponto = Point(long, lat)\n",
    "        cidade = malha[malha.geometry.contains(ponto)]\n",
    "\n",
    "        if not cidade.empty:\n",
    "            df.at[indice, \"CIDADE\"] = cidade.iloc[0][\"Municipio\"]\n",
    "            cont_alteracoes = cont_alteracoes + 1\n",
    "\n",
    "\n",
    "print(f\"Foram feitas {cont_alteracoes} alteraçoes\")\n",
    "df.to_csv('dados/SpSafe_2022.csv', index=False, sep=';', encoding='utf-8')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p> Erros por falta de latitude e longitude </p>\n",
    "<p> Tratamento correlacionando com um DF de delegacias -> cidades encontrada via secretária de segurança pública de São Paulo </p>\n",
    "<a href=\"https://portalgeo.seade.gov.br/\">Clique aqui para visitar o site</a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DM BIRIGUI' '1 DP SE' '2 DP BOM RETIRO' ... 'DELINVGER JUNDIAI'\n",
      " 'DELINFJUV SOROCABA' 'DISE DELSECFRANCO DA ROCHA']\n"
     ]
    }
   ],
   "source": [
    "delegacias = df[\"DELEGACIA_CIRCUNSCRICAO\"].unique()\n",
    "print(delegacias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p> Abaixo vamos fazer uma pre-normalização  a escrita do dataFrame de delegacias, tirando simbolos, acentos</p>\n",
    "<p> A biblioteca unicodedate foi responsável por essa normalização </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02 DP JACAREI\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def remove_simbolos(texto):\n",
    "    texto = str(texto)\n",
    "\n",
    "    # Remove símbolos específicos antes da normalização\n",
    "    texto = texto.replace(\"º\", \"\")  # ordinal masculino\n",
    "    texto = texto.replace(\"ª\", \"\")  # ordinal feminino\n",
    "    texto = texto.replace(\"°\", \"\")  # grau\n",
    "\n",
    "    # Normaliza (remove acentos)\n",
    "    texto = unicodedata.normalize(\"NFKD\", texto)\n",
    "\n",
    "    # Remove qualquer caractere que não seja letra, número ou espaço\n",
    "    texto = ''.join(c for c in texto if c.isalnum() or c.isspace())\n",
    "\n",
    "    return texto\n",
    "\n",
    "df[\"DELEGACIA_ELABORACAO\"] = df[\"DELEGACIA_ELABORACAO\"].apply(remove_simbolos)\n",
    "\n",
    "print(remove_simbolos(\"02º D.P. JACAREIº\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p> Agora usamos uma biblioteca chamada RapidFuzz, para encontrar casamentos por similaridades usando o algoritimo\n",
    "    distancia Levenshtein, que classifica as similaridade de duas strings em um valor númerico de 0 a 100  </p>\n",
    "<p> Também usamos a biblioteca re, que trabalha com substituição/remoção de padrões \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substituições concluídas.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_delegacias = pd.read_csv(\"dados/DADOS CRIMINAIS.csv\", delimiter=',')\n",
    "\n",
    "def preprocessar_string(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[^\\w\\s]', '', s)  # [] Toda palavra ^negação \\w Letras, números e underscore \\s espaço\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    s = re.sub(r'^0+(\\d+)', r'\\1', s)\n",
    "    return s\n",
    "\n",
    "# Preprocessa todas as delegacias\n",
    "df_delegacias[\"DP_PREP\"] = df_delegacias[\"DP\"].astype(str).apply(preprocessar_string)\n",
    "\n",
    "def procura_similaridade(delegacia):\n",
    "    s = preprocessar_string(str(delegacia))\n",
    "    match = process.extractOne(\n",
    "        s,\n",
    "        df_delegacias[\"DP_PREP\"],\n",
    "        scorer=fuzz.ratio\n",
    "    )\n",
    "    if match and match[1] >= 90:\n",
    "        idx = df_delegacias[\"DP_PREP\"][df_delegacias[\"DP_PREP\"] == match[0]].index[0]\n",
    "        return df_delegacias.loc[idx, \"MUNICIPIO\"]\n",
    "    return np.nan\n",
    "\n",
    "# Aplica nos registros com cidade nula\n",
    "mascara = df[\"CIDADE\"].isna()\n",
    "df.loc[mascara, \"CIDADE\"] = df.loc[mascara, \"DELEGACIA_ELABORACAO\"].apply(procura_similaridade)\n",
    "\n",
    "print(\"Substituições concluídas.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p> Ruidos de cidades com valor 2513851.0, que corresponde a cidade de Santo André </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados atualizados com sucesso.\n"
     ]
    }
   ],
   "source": [
    "df.loc[df[\"CIDADE\"] == \"2513851.0\", \"CIDADE\"] = \"Santo Andre\"\n",
    "\n",
    "df.to_csv('dados/SpSafe_2022.csv', index=False, sep=';', encoding='utf-8')\n",
    "print(\"Dados atualizados com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p> Algumas correções que faltaram  com  maiores repetições </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DELEGACIA_ELABORACAO\n",
       "DELEGACIA ELETRONICA        51844\n",
       "DELEGACIA ELETRONICA 1       3833\n",
       "DELEGACIA ELETRONICA 3       2262\n",
       "DELEGACIA ELETRONICA 2       1322\n",
       "73 DP JACANA                  672\n",
       "                            ...  \n",
       "DELSECARARAQUARA                1\n",
       "DELPOLMIRA ESTRELA              1\n",
       "45 DP V BRASILANDIA             1\n",
       "1 DIG  DEIC  DEINTER 6          1\n",
       "SETOR HOMSEC SANTO ANDRE        1\n",
       "Name: count, Length: 796, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delegacias_agrupadas = df[df[\"CIDADE\"].isnull()][\"DELEGACIA_ELABORACAO\"].value_counts()\n",
    "delegacias_agrupadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alterações realizadas com sucesso.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for indice, linha in df[df[\"CIDADE\"].isnull()].iterrows():\n",
    "    if linha[\"DELEGACIA_ELABORACAO\"] == \"73 DP JACANA\":\n",
    "        df.at[indice, \"CIDADE\"] = \"São Paulo\"\n",
    "    elif linha[\"DELEGACIA_ELABORACAO\"] == \"PLANTAO DE SOROCABA  Z NORTE\":\n",
    "        df.at[indice, \"CIDADE\"] = \"Sorocaba\"\n",
    "    elif linha[\"DELEGACIA_ELABORACAO\"] == \"CPJ RIBEIRAO PRETO\":\n",
    "        df.at[indice, \"CIDADE\"] = \"Ribeirão Preto\"\n",
    "    elif linha[\"DELEGACIA_ELABORACAO\"] == \"DELPOLPLANTAO SUMARE\":\n",
    "        df.at[indice, \"CIDADE\"] = \"Sumaré\"\n",
    "    elif linha[\"DELEGACIA_ELABORACAO\"] == \"101 DP JDIM IMBUIAS\":\n",
    "        df.at[indice, \"CIDADE\"] = \"Jardim das Imbuias\"\n",
    "    elif linha[\"DELEGACIA_ELABORACAO\"] == \"89 DP JARDIM TABOAO\":\n",
    "        df.at[indice, \"CIDADE\"] = \"São Paulo\"\n",
    "    elif linha[\"DELEGACIA_ELABORACAO\"] == \"DELSECFRANCA PLANTAO\":\n",
    "        df.at[indice, \"CIDADE\"] = \"Franca\"\n",
    "    elif linha[\"DELEGACIA_ELABORACAO\"] == \"DELSECITANHAEM PLANTAO\":\n",
    "        df.at[indice, \"CIDADE\"] = \"Itanhaém\"\n",
    "    elif linha[\"DELEGACIA_ELABORACAO\"] == \"CPJ LINS\":\n",
    "        df.at[indice, \"CIDADE\"] = \"Lins\"\n",
    "    elif linha[\"DELEGACIA_ELABORACAO\"] == \"27 DP DR IGNACIO FRANCISCO\":\n",
    "        df.at[indice, \"CIDADE\"] = \"São Paulo\"\n",
    "    elif linha[\"DELEGACIA_ELABORACAO\"] == \"DELSECRIO CLARO PLANTAO\":\n",
    "        df.at[indice, \"CIDADE\"] = \"Rio Claro\"\n",
    "\n",
    "print(\"Alterações realizadas com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo com sucesso\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('dados/SpSafe_2022.csv', index=False, sep=';', encoding='utf-8')\n",
    "print(\"Salvo com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "malha_demografica = gpd.read_file(\"dados/Dados Demograficos/Den Demografica.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CIDADE\n",
       "São Paulo                316640\n",
       "Santo Andre               21807\n",
       "Guarulhos                 19332\n",
       "Campinas                  18918\n",
       "São Bernardo do Campo     16913\n",
       "                          ...  \n",
       "Sagres                        1\n",
       "Emilianópolis                 1\n",
       "Nova Canaã Paulista           1\n",
       "Cabrália Paulista             1\n",
       "Uru                           1\n",
       "Name: count, Length: 656, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cidades_agrupadas = df[\"CIDADE\"].dropna().value_counts()\n",
    "cidades_agrupadas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
