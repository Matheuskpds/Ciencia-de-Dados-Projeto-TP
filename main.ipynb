{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste projeto, desenvolvido no √¢mbito da disciplina CCF425 - Introdu√ß√£o √† Ci√™ncia\n",
    "dos Dados, buscamos aplicar os conceitos te√≥ricos aprendidos em sala de aula para analisar\n",
    "conjuntos de dados reais e desafiadores. O trabalho est√° dividido em cinco etapas, cada uma\n",
    "com objetivos espec√≠ficos, culminando em uma apresenta√ß√£o final que destaca as principais\n",
    "descobertas.\n",
    "Nesta primeira etapa, nosso foco √© o entendimento inicial dos dados e sua prepara√ß√£o.\n",
    "Trabalharemos com um dos conjuntos de dados dispon√≠veis: Dados de criminalidade de SP\n",
    "(SPSafe) ou Dados demogr√°ficos dos munic√≠pios brasileiros (BrStats), dependendo da turma\n",
    "pr√°tica. Nosso grupo ficou respons√°vel pelo conjunto de dados do SPSafe. O objetivo √©\n",
    "explorar os atributos presentes, identificar poss√≠veis ru√≠dos, tratar informa√ß√µes ausentes e\n",
    "formular pelo menos 10 perguntas que guiar√£o nossas an√°lises futuras. Al√©m disso,\n",
    "realizaremos ajustes na formata√ß√£o dos dados, enriquecimento com atributos externos e\n",
    "outras atividades necess√°rias para garantir a qualidade da base de dados.\n",
    "A entrega desta etapa inclui a cria√ß√£o de um projeto no GitHub, onde disponibilizaremos um\n",
    "arquivo README com os integrantes do grupo, as perguntas elaboradas, o c√≥digo utilizado e\n",
    "um relat√≥rio parcial documentando as decis√µes tomadas e suas justificativas. Cada integrante\n",
    "contribuir√° ativamente, e suas a√ß√µes ser√£o registradas no hist√≥rico de commits e na\n",
    "documenta√ß√£o.\n",
    "Esta fase √© fundamental para estabelecer as bases do projeto, garantindo que os dados\n",
    "estejam prontos para as an√°lises explorat√≥rias e t√©cnicas mais avan√ßadas que ser√£o aplicadas\n",
    "nas etapas subsequentes. Com um trabalho bem estruturado desde o in√≠cio, estaremos\n",
    "preparados para enfrentar os desafios t√≠picos da Ci√™ncia de Dados e extrair insights valiosos\n",
    "dos conjuntos de dados selecionados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pap√©is de cada integrante**\n",
    "Todos os integrantes tiveram papel fundamental no decorrer do trabalho at√© aqui, seja\n",
    "contribuindo com as ideias e perguntas, ou seja contribuindo com desenvolvimento dos\n",
    "c√≥digos. A seguir detalharemos o papel de cada integrante:\n",
    "\n",
    "‚û¢ Arthur Teodoro: Participou ativamente no desenvolvimento e decis√£o das das\n",
    "perguntas, na elabora√ß√£o do relat√≥rio e foi respons√°vel pela implementa√ß√£o da adi√ß√£o\n",
    "dos dados externos de ‚ÄúDatas At√≠picas‚Äù.\n",
    "\n",
    "‚û¢ Gabriel Benez: Participou na cria√ß√£o e decis√£o de quais perguntas selecionar, na\n",
    "elabora√ß√£o do relat√≥rio e tamb√©m foi respons√°vel pela a implementa√ß√£o do c√≥digo que\n",
    "preenche os dados vazios do campo ‚ÄúCidade‚Äù, e detec√ß√£o de alguns ru√≠dos.\n",
    "\n",
    "‚û¢ Lucas Fonseca: Participou ativamente no desenvolvimento e decis√£o das das\n",
    "perguntas, na elabora√ß√£o do relat√≥rio e foi respons√°vel pela implementa√ß√£o e melhora da adi√ß√£o\n",
    "dos dados externos de ‚ÄúIncidentes‚Äù, remo√ß√£o de dados dublipcados,adi√ß√£o de correla√ß√£o e gr√°ficos de;\n",
    "\"Quantidade de BO's por dia na semana\", \"Rela√ß√£o quantidades BO's com periodo do Dia\",\n",
    "\"Dias da semana t√™m maior incid√™ncia de invas√µes domiciliares (Pergunta 8)\", associatividade entre tipo de crimes e o local de alabora√ß√£o do BO, e associa√ß√£o de datas de jogos de futebol com tipo de crimes.\n",
    "\n",
    "‚û¢ Matheus Kauan: Respons√°vel pela cria√ß√£o do reposit√≥rio e adi√ß√£o dos\n",
    "colaboradores. Participou ativamente no desenvolvimento e nas escolhas das\n",
    "perguntas e tamb√©m trabalhou na adi√ß√£o/cria√ß√£o de uma nova coluna no dataframe\n",
    "inserindo os dias da semana correspondente a data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "import math\n",
    "import geopandas as gpd\n",
    "import re\n",
    "from rapidfuzz import process, fuzz\n",
    "import unicodedata\n",
    "import matplotlib.pyplot as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 align=\"center\"> Baixar o arquivo csv, caso n√£o tenha baixado o arquivo via github:</H2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tenta importar gdown, se n√£o conseguir, instala\n",
    "try:\n",
    "    import gdown  # Tenta importar novamente ap√≥s a instala√ß√£o\n",
    "except ImportError:\n",
    "    print(\"üì• gdown n√£o encontrado. Instalando automaticamente...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"gdown\"])\n",
    "\n",
    "# Baixar o arquivo do Google Drive\n",
    "\n",
    "file_id = \"1VbB_fvowkgNoWcLADi1mEfFjWQI6nBjp\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "output = \"dados/SpSafe_2022.csv\"\n",
    "\n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  Leitura do arquivo\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('dados/SpSafe_2022.csv', delimiter=';')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando os diferentes tipos de crimes registrados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NATUREZA_APURADA'].dropna().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados nulos para profiss√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pensamos em analisar a correla√ß√£o das v√≠timas e suas profiss√µes, mas grande parte dos dados s√£o nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentagem_nan_prof = df['PROFISSAO'].isna().mean() * 100\n",
    "print(f\"{porcentagem_nan_prof:.2f}% dos dados s√£o NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria√ß√£o do dicion√°rio dos campos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_boletim = {\n",
    "    \"Nome do Campo\": [\n",
    "        \"NUM BO\", \"ANO BO\", \"CODIGO BOLETIM\", \"NATUREZA APURADA\", \"DATA OCORRENCIA\", \"HORA OCORRENCIA\", \"PERIODO OCORRENCIA\",\n",
    "        \"CIDADE\", \"COD IBGE\", \"LOGRADOURO\", \"NUMERO LOGRADOURO\", \"BAIRRO\", \"UF\", \"TIPO LOCAL\", \"LATITUDE\", \"LONGITUDE\", \"PONTO CRIME\",\n",
    "        \"DELEGACIA ELABORACAO\", \"DEPARTAMENTO ELABORACAO\", \"SECCIONAL ELABORACAO\", \"TIPO PESSOA\", \"GENERO PESSOA\", \"IDADE PESSOA\",\n",
    "        \"DATA NASCIMENTO PESSOA\", \"COR PELE\", \"PROFISSAO\", \"PLACA VEICULO\", \"UF VEICULO\", \"CIDADE VEICULO\", \"COR VEICULO\",\n",
    "        \"MARCA VEICULO\", \"MODELO VEICULO\", \"ANO FABRICACAO\", \"ANO MODELO\", \"TIPO VEICULO\", \"MARCA CELULAR\", \"QUANT CELULAR\",\n",
    "        \"BO INICIADO\", \"BO EMITIDO\", \"DATA HORA ELABORACAO\", \"DATA COMUNICACAO\", \"BO AUTORIA\", \"FLAGRANTE\", \"EXAME\", \"SOLUCAO\",\n",
    "        \"ESPECIE\", \"STATUS\", \"FLAG VITIMA FATAL\", \"DESDOBRAMENTO\"\n",
    "    ],\n",
    "    \"Descri√ß√£o do Campo\": [\n",
    "        \"N√∫mero do boletim de ocorr√™ncia\", \"Ano do boletim de ocorr√™ncia\", \"Jun√ß√£o do n√∫mero com o ano do BO separados por '/'\",\n",
    "        \"Tipo de crime cometido\", \"Data em que o crime ocorreu\", \"Hora em que o crime ocorreu\", \"Per√≠odo do dia em que o crime ocorreu\",\n",
    "        \"Cidade em que o crime ocorreu\", \"C√≥digo da cidade (IBGE)\", \"Via em que o crime ocorreu\",\n",
    "        \"N√∫mero do local do crime\", \"Bairro do crime\", \"UF do crime\", \"Tipo de local do crime\",\n",
    "        \"Latitude do ponto do crime\", \"Longitude do ponto do crime\", \"Ponto geogr√°fico no formato WKT\",\n",
    "        \"Delegacia que elaborou o BO\", \"Departamento que elaborou o BO\", \"Seccional que elaborou o BO\",\n",
    "        \"Indica se √© v√≠tima ou autor\", \"G√™nero\", \"Idade\", \"Data de nascimento\", \"Cor da pele\", \"Profiss√£o\",\n",
    "        \"Placa do ve√≠culo\", \"UF do emplacamento\", \"Cidade do emplacamento\", \"Cor do ve√≠culo\",\n",
    "        \"Marca do ve√≠culo\", \"Modelo do ve√≠culo\", \"Ano de fabrica√ß√£o\", \"Ano do modelo\", \"Tipo de ve√≠culo\",\n",
    "        \"Marca do celular\", \"Quantidade de celulares\", \"Data/hora em que o BO foi iniciado\", \"Data/hora em que o BO foi conclu√≠do\",\n",
    "        \"Data/hora de elabora√ß√£o do BO\", \"Data em que o BO foi comunicado\", \"Respons√°vel pelo BO\",\n",
    "        \"Indica se foi flagrante\", \"Respons√°vel pelo exame\", \"Tipo de solu√ß√£o do crime\",\n",
    "        \"Esp√©cie de patrim√¥nio\", \"Status do crime\", \"Indica se houve v√≠tima fatal\", \"Desdobramento do caso\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_dicionario = pd.DataFrame(dados_boletim)\n",
    "df_dicionario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entendermos se h√° alguma correla√ß√£o entre o dia da semana e os crimes cometidos, foi criada uma nova coluna com os dias da semana que obtivemos a partir da data da ocorr√™ncia do crime. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 align=\"center\"> C√≥digos criados para adicionar uma coluna com os atributos dia da semana. </H2>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P aling = \"center\">  </P>\n",
    "<p align=\"center\">\n",
    "  Executar somente quando um novo arquivo for baixado do Google Drive\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T02:44:53.743629Z",
     "start_time": "2025-03-29T02:44:53.684912Z"
    }
   },
   "outputs": [],
   "source": [
    "#Conventendo a coluna DATA_OCORRENCIA para datetime para ser reconhecido como data pelo pandas\n",
    "df['DATA_OCORRENCIA'] = pd.to_datetime(df['DATA_OCORRENCIA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria√ß√£o de coluna com o dia da semana\n",
    "df.insert(df.columns.get_loc('DATA_OCORRENCIA') + 1, 'DIA_SEMANA', df['DATA_OCORRENCIA'].dt.day_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T02:44:59.246077Z",
     "start_time": "2025-03-29T02:44:59.110796Z"
    }
   },
   "outputs": [],
   "source": [
    "#Convertendo os dias da semana para portugu√™s\n",
    "dias_semana = {\n",
    "    'Monday': 'SEGUNDA-FEIRA', 'Tuesday': 'TER√áA-FEIRA', 'Wednesday': 'QUARTA-FEIRA',\n",
    "    'Thursday': 'QUINTA-FEIRA', 'Friday': 'SEXTA-FEIRA', 'Saturday': 'S√ÅBADO', 'Sunday': 'DOMINGO'\n",
    "}\n",
    "df['DIA_SEMANA'] = df['DATA_OCORRENCIA'].dt.day_name().map(dias_semana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 align=\"center\"> C√≥digos criados para verificar se a data teve um evento at√≠pico. </H2>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devido h√° v√°rios eventos e datas comemorativas que ocorrem durante o ano, um novo atributo ser√° adicionado para entendermos se h√° uma correla√ß√£o entre a data espec√≠fica e quantidade de crimes cometidos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  Executar somente para o arquivo csv baixado via Google Drive\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir os eventos de S√£o Paulo em 2022\n",
    "eventos_sp_2022 = [\n",
    "    #Feriados em Sp 2022:\n",
    "    '2022-01-01',  # Confraterniza√ß√£o Universal\n",
    "    '2022-04-15',  # Paix√£o de Cristo\n",
    "    '2022-04-21',  # Tiradentes\n",
    "    '2022-05-01',  # Dia do Trabalho\n",
    "    '2022-09-07',  # Independ√™ncia do Brasil\n",
    "    '2022-10-12',  # Nossa Senhora Aparecida\n",
    "    '2022-11-02',  # Finados\n",
    "    '2022-11-15',  # Proclama√ß√£o da Rep√∫blica\n",
    "    '2022-12-25',  # Natal\n",
    "    '2022-07-09',  # Revolu√ß√£o Constitucionalista\n",
    "    '2022-02-28',  # Carnaval\n",
    "    '2022-03-01',  # Carnaval\n",
    "    '2022-06-16',  # Corpus Christi\n",
    "    '2022-10-28',  # Dia do Servidor P√∫blico\n",
    "    \n",
    "    #Facultativos:\n",
    "    '2022-03-02',  # Quarta-Feira de Cinzas\n",
    "    '2022-12-24',  # V√©spera de Natal\n",
    "    '2022-12-31',   # V√©spera de Ano Novo\n",
    "\n",
    "    '2022-01-25',  # Final da Copa S√£o Paulo de Futebol J√∫nior\n",
    "    '2022-03-10',  # Palmeiras x S√£o Paulo - Paulista\n",
    "    '2022-03-30',  # Final Paulista - Jogo 1\n",
    "    '2022-04-03',  # Final Paulista - Jogo 2\n",
    "    '2022-05-02',  # S√£o Paulo x Santos - Brasileir√£o\n",
    "    '2022-05-22',  # Corinthians x S√£o Paulo - Brasileir√£o\n",
    "    '2022-06-20',  # S√£o Paulo x Palmeiras - Brasileir√£o\n",
    "    '2022-08-21',  # Santos x S√£o Paulo - Brasileir√£o\n",
    "    '2022-09-11',  # S√£o Paulo x Corinthians - Brasileir√£o\n",
    "    '2022-10-16',  # Palmeiras x S√£o Paulo - Brasileir√£o\n",
    "    \n",
    "    # Jogos da Copa do Mundo 2022 (Sele√ß√£o Brasileira)\n",
    "    '2022-11-24',  # Brasil 2 x 0 S√©rvia\n",
    "    '2022-11-28',  # Brasil 1 x 0 Su√≠√ßa\n",
    "    '2022-12-02',  # Camar√µes 1 x 0 Brasil\n",
    "    '2022-12-05',  # Brasil 4 x 1 Coreia do Sul (Oitavas)\n",
    "    '2022-12-09'   # Brasil 1(2) x (4)1 Cro√°cia (Quartas)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conventendo a coluna DATA_OCORRENCIA para datetime para ser reconhecido como data pelo pandas\n",
    "df['DATA_OCORRENCIA'] = pd.to_datetime(df['DATA_OCORRENCIA'])\n",
    "\n",
    "# Converter para datetime para compara√ß√£o\n",
    "eventos_dates = pd.to_datetime(eventos_sp_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar nova coluna 'DIA ATIPICO' que indica se na data aconteceu um evento at√≠pico:\n",
    "df['DIA ATIPICO'] = df['DATA_OCORRENCIA'].isin(eventos_dates)\n",
    "\n",
    "#Converter para texto mais descritivo\n",
    "df['DIA ATIPICO'] = df['DIA ATIPICO'].map({True: 'SIM', False: 'N√ÉO'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head(20)\n",
    "\n",
    "# Filtrar o DataFrame para retornar apenas as linhas onde 'DIA ATIPICO' √© 'SIM'\n",
    "df_atipico = df[df['DIA ATIPICO'] == 'SIM']\n",
    "# Exibir o resultado\n",
    "df_atipico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao analisarmos o dataset, detectamos alguns problemas com certas informa√ß√µes que apresentam dados nulos: falta de nomes das cidades e aus√™ncia de per√≠odos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de PERIODO_OCORRENCIA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando Objetos que 'PERIODO_OCORRENCIA' s√£o \"NaN\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nam = df[df['PERIODO_OCORRENCIA'].isna()]\n",
    "df_nam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando Objetos que 'PERIODO_OCORRENCIA' e 'HORA_OCORRENCIA' s√£o \"NaN\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = df['HORA_OCORRENCIA'].isna().astype(bool)\n",
    "mask2 = df['PERIODO_OCORRENCIA'].isna().astype(bool)\n",
    "df_nam = df[mask1 & mask2]  # or mask1 | mask2 for OR condition\n",
    "df_nam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtro de Tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Filtra linhas onde PERIODO_OCORRENCIA √© nulo (usando isna)\n",
    "df_nam = df[df['PERIODO_OCORRENCIA'].isna()].copy()\n",
    "\n",
    "# 2. Atualiza PERIODO_OCORRENCIA baseado em HORA_OCORRENCIA (formato \"HH:MM:SS\")\n",
    "def definir_periodo(hora_str):\n",
    "    if pd.isna(hora_str):\n",
    "        return \"EM HORA INCERTA\"\n",
    "    \n",
    "    try:\n",
    "        hora_part = hora_str.split(':')[0]\n",
    "        hora = int(hora_part)\n",
    "    except (ValueError, IndexError, AttributeError):\n",
    "        return \"EM HORA INCERTA\"\n",
    "    \n",
    "    if 0 <= hora < 5:\n",
    "        return \"DE MADRUGADA\"\n",
    "    elif 5 <= hora < 12:\n",
    "        return \"PELA MANH√É\"\n",
    "    elif 12 <= hora < 18:\n",
    "        return \"A TARDE\"\n",
    "    elif 18 <= hora <= 23:\n",
    "        return \"A NOITE\"\n",
    "    else:\n",
    "        return \"EM HORA INCERTA\"\n",
    "\n",
    "# Aplica a fun√ß√£o para atualizar os valores\n",
    "df_nam['PERIODO_OCORRENCIA'] = df_nam['HORA_OCORRENCIA'].apply(definir_periodo)\n",
    "\n",
    "# Verifica o resultado\n",
    "df_nam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atualiza o DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PERIODO_OCORRENCIA'] = np.where(\n",
    "    df['PERIODO_OCORRENCIA'].isna(),\n",
    "    df['HORA_OCORRENCIA'].apply(definir_periodo),\n",
    "    df['PERIODO_OCORRENCIA']\n",
    ")\n",
    "\n",
    "df[df['PERIODO_OCORRENCIA'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incidentes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria√ß√£o do campo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Criar uma coluna combinada para o local de elabora√ß√£o\n",
    "df['LOCAL_ELABORACAO'] = df['DELEGACIA_ELABORACAO'].fillna(\n",
    "                          df['DEPARTAMENTO_ELABORACAO'].fillna(\n",
    "                          df['SECCIONAL_ELABORACAO']))\n",
    "\n",
    "# Definir as colunas para agrupar os incidentes\n",
    "dados_incidente = ['DATA_OCORRENCIA', 'PERIODO_OCORRENCIA', \n",
    "                   'LOGRADOURO', 'NUMERO_LOGRADOURO', 'BAIRRO', \n",
    "                   'UF', 'TIPO_LOCAL', 'LOCAL_ELABORACAO','DIA_SEMANA']\n",
    "\n",
    "# Criar os IDs de incidentes com base no agrupamento\n",
    "df['INCIDENTES_ID'] = df.groupby(dados_incidente, dropna=False).ngroup() + 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Incidentes sem Id\n",
    "df[df['INCIDENTES_ID'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantidade de Incidentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar apenas registros que pertencem a incidentes (excluindo poss√≠veis registros sem agrupamento)\n",
    "dados_com_incidentes = df[df['INCIDENTES_ID'].notna()]\n",
    "\n",
    "# Mostrar esses dados\n",
    "dados_com_incidentes.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revis√£o da an√°lise inicial e tratamentos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atributos externos adicionados\n",
    "Para responder todas estas quest√µes ser√° necess√°rio um pouco mais que os dados\n",
    "disponibilizados no Sp Safe, por este motivo, adicionaremos mais informa√ß√µes que ser√£o\n",
    "essenciais para a an√°lise e entendimento dos dados. As novas adi√ß√µes foram:\n",
    "\n",
    "1) Dias da semana:\n",
    "Como buscamos tra√ßar um padr√£o de comportamento baseado em per√≠odos da semana, foi\n",
    "necess√°rio transcrever as datas dos ocorridos para seus respectivos dias da semana. Para isso\n",
    "utilizamos ‚Äúdf['DATA_OCORRENCIA'].dt.day_name()‚Äù, que vai extrair da data da\n",
    "ocorr√™ncia o seu dia da semana, possibilitando fazer a an√°lise de um poss√≠vel padr√£o semanal.\n",
    "\n",
    "2) Eventos at√≠picos:\n",
    "Entender se h√° uma rela√ß√£o entre crimes ocorridos e dias ‚Äún√£o rotineiros‚Äù faz parte dos\n",
    "in√∫meros objetivos deste projeto, logo, precisamos conhecer as datas de grandes eventos que\n",
    "movimentaram a popula√ß√£o no ano de 2022. Para isso adicionamos um conjunto de datas\n",
    "marcantes no ano de 2022, como, por exemplo, feriados relevantes e jogos importantes.\n",
    "Usando estes dados exteriores podemos identificar crimes que ocorreram em datas e eventos\n",
    "movimentados e entender como se correlacionam.\n",
    "\n",
    "3) Incidentes:\n",
    "Com a finalidade de agrupar os crimes juntos, podemos observar que no banco de dados pode\n",
    "ser que um crime tenha ocorrido como uma invas√£o de propriedade e tenha ocorrido um\n",
    "furto. Esses dois crimes s√£o considerados distintos, um sendo de invas√£o de propriedade e o\n",
    "outro de furto. Ent√£o, √© interessante criar um novo atributo que identifique incidentes. Se\n",
    "houver informa√ß√µes iguais em outros atributos, significa que provavelmente s√£o do mesmo\n",
    "incidente, ocorreram ao mesmo tempo e com a mesma pessoa.\n",
    "Com o tratamento de dados atual, que ainda apresenta muitos registros em branco, foi\n",
    "poss√≠vel associar um n√∫mero de incidente a 20.556 BOs (Boletins de Ocorr√™ncia). No\n",
    "entanto, o dataset completo cont√©m 720.446 registros. Essa diferen√ßa evidencia a necessidade\n",
    "de complementar as informa√ß√µes faltantes, pois s√≥ assim ser√° poss√≠vel determinar se um\n",
    "3\n",
    "determinado BO ou crime faz parte de um conjunto de ocorr√™ncias relacionadas a um mesmo\n",
    "incidente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tratamento de aus√™ncia de dados**\n",
    "Para responder as perguntas escolhidas precisar√≠amos da completude de alguns campos, o que\n",
    "nem sempre ocorre. Veja algumas destas demandas e suas solu√ß√µes abaixo:\n",
    "1) Falta de nomes de cidades:\n",
    "Para resolver este problema, usamos a biblioteca ‚Äúgeopy‚Äù para recuperar o nome da cidade\n",
    "onde o crime descrito ocorreu usando sua latitude e longitude. Essa biblioteca pega os valores\n",
    "de latitude e longitude, e por meio de uma API, recupera o endere√ßo onde essas coordenadas\n",
    "batem, retornando a informa√ß√£o faltante no campo ‚Äúcidade‚Äù.\n",
    "2) Aus√™ncia de per√≠odos:\n",
    "Alguns registros de BO n√£o possuem seus per√≠odos registrados de acordo seus respectivos\n",
    "hor√°rios, apresentando valores nulos (NaN). Com base nas informa√ß√µes do SPSafe, o turnos\n",
    "do periodo foram adicionados a partir desses hor√°rios registrados, foi feito, primeiramente,\n",
    "filtrando o dataframe para exibir as linhas de dados em que esse fator ocorre e em seguida foi\n",
    "aplicada a l√≥gica para adi√ß√£o dos turnos. Ap√≥s o tratamentos desses dados nulos, foram\n",
    "acrescentadas mais de 6 mil novas linhas sem dados nulos na coluna de\n",
    "PERIODO_OCORRENCIA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ru√≠dos detectados:**\n",
    "1) Erro na digita√ß√£o ou formata√ß√£o dos dados de latitude e longitude.\n",
    "Foi detectado alguns erros na digita√ß√£o dos dados do campo ‚Äúlatitude‚Äù e ‚Äúlongitude‚Äù do\n",
    "dataframe. Um desses erros foi o valor num√©rico que n√£o corresponde ao padr√£o usado\n",
    "para identificar as coordenadas, e deslocamento da v√≠rgula.\n",
    "2) BO‚Äôs com idade igual a 0:\n",
    "Foi detectado tamb√©m alguns BO's em que o autor/v√≠tima possui 0 anos de idade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">\n",
    "  C√≥digos criados para localizar as cidades dos dados via latitude e longitude\n",
    "</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<strong>Diferente da primeira entrega, usamos o geopanda para mapear as cidades via latitude e longitude usando shapefile da Funda√ß√£o Seade (Sistema Estadual de An√°lise de Dados)</strong>\n",
    "<br>\n",
    "<a href=\"https://portalgeo.seade.gov.br/\">Clique aqui para visitar o site</a>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malha = gpd.read_file(\"dados/Shapefile/LimiteMunicipal.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p> Percorremos cada linha, cruzando os dados do dataframe SpSafe com o que foi gerado com o shapefile da base geogr√°fica dos munic√≠pios de S√£o Paulo </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contador_erro = 0\n",
    "for indice, linha in df.iloc[1:].iterrows():\n",
    "\tif pd.isna(linha[\"LATITUDE\"]) and pd.isna(linha[\"LONGITUDE\"]):\n",
    "\t\tcontinue\n",
    "\tif pd.isna(linha[\"CIDADE\"]) and pd.notna(linha[\"LATITUDE\"]) and pd.notna(linha[\"LONGITUDE\"]):\n",
    "\t\tponto = Point(linha[\"LONGITUDE\"], linha[\"LATITUDE\"])\n",
    "\t\tcidade = malha[malha.geometry.contains(ponto)]\n",
    "\t\tif not cidade.empty:\n",
    "\t\t\tdf.at[indice, \"CIDADE\"] = cidade.iloc[0][\"Municipio\"]\n",
    "\t\telse:\n",
    "\t\t\tcontador_erro = contador_erro + 1\n",
    "\t\t\tdf.iloc[indice, \"LATITUDE\", \"LONGITUDE\"]\n",
    "\tif(contador_erro >= 10 and contador_erro % 10 == 0):\n",
    "\t\tprint(f\"{contador_erro} erros.\")\n",
    "\n",
    "df.to_csv('dados/SpSafe_2022.csv', index=False, sep=';', encoding='utf-8')\n",
    "print(\"Gravado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<h2> Tratamentos de erros</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p> Erros por latitude com virgula em posi√ß√£o incorreta </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificaMag(valor):\n",
    "    if valor == 0:\n",
    "        return 0\n",
    "    return math.floor(math.log10(abs(valor))) - 1\n",
    "\n",
    "cont_alteracoes = 0\n",
    "\n",
    "for indice, linha in df.iloc[1:].iterrows():\n",
    "    if(pd.isna(linha[\"CIDADE\"]) and pd.notna(linha[\"LATITUDE\"]) and pd.notna(linha[\"LONGITUDE\"])):\n",
    "        lat = linha[\"LATITUDE\"] / 10 ** verificaMag(linha[\"LATITUDE\"])\n",
    "        long = linha[\"LONGITUDE\"] / 10 ** verificaMag(linha[\"LONGITUDE\"])\n",
    "        ponto = Point(long, lat)\n",
    "        cidade = malha[malha.geometry.contains(ponto)]\n",
    "\n",
    "        if not cidade.empty:\n",
    "            df.at[indice, \"CIDADE\"] = cidade.iloc[0][\"Municipio\"]\n",
    "            cont_alteracoes = cont_alteracoes + 1\n",
    "\n",
    "\n",
    "print(f\"Foram feitas {cont_alteracoes} altera√ßoes\")\n",
    "df.to_csv('dados/SpSafe_2022.csv', index=False, sep=';', encoding='utf-8')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p> Erros por falta de latitude e longitude </p>\n",
    "<p> Tratamento correlacionando com um DF de delegacias -> cidades encontrada via secret√°ria de seguran√ßa p√∫blica de S√£o Paulo </p>\n",
    "<a href=\"https://portalgeo.seade.gov.br/\">Clique aqui para visitar o site</a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delegacias = df[\"DELEGACIA_CIRCUNSCRICAO\"].unique()\n",
    "print(delegacias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p> Abaixo vamos fazer uma pre-normaliza√ß√£o  a escrita do dataFrame de delegacias, tirando simbolos, acentos</p>\n",
    "<p> A biblioteca unicodedate foi respons√°vel por essa normaliza√ß√£o </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_simbolos(texto):\n",
    "    texto = str(texto)\n",
    "\n",
    "    # Remove s√≠mbolos espec√≠ficos antes da normaliza√ß√£o\n",
    "    texto = texto.replace(\"¬∫\", \"\")  # ordinal masculino\n",
    "    texto = texto.replace(\"¬™\", \"\")  # ordinal feminino\n",
    "    texto = texto.replace(\"¬∞\", \"\")  # grau\n",
    "\n",
    "    # Normaliza (remove acentos)\n",
    "    texto = unicodedata.normalize(\"NFKD\", texto)\n",
    "\n",
    "    # Remove qualquer caractere que n√£o seja letra, n√∫mero ou espa√ßo\n",
    "    texto = ''.join(c for c in texto if c.isalnum() or c.isspace())\n",
    "\n",
    "    return texto\n",
    "\n",
    "df[\"DELEGACIA_ELABORACAO\"] = df[\"DELEGACIA_ELABORACAO\"].apply(remove_simbolos)\n",
    "\n",
    "print(remove_simbolos(\"02¬∫ D.P. JACAREI¬∫\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p> Agora usamos uma biblioteca chamada RapidFuzz, para encontrar casamentos por similaridades usando o algoritimo\n",
    "    distancia Levenshtein, que classifica as similaridade de duas strings em um valor n√∫merico de 0 a 100  </p>\n",
    "<p> Tamb√©m usamos a biblioteca re, que trabalha com substitui√ß√£o/remo√ß√£o de padr√µes \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_delegacias = pd.read_csv(\"dados/DADOS CRIMINAIS.csv\", delimiter=',')\n",
    "\n",
    "def preprocessar_string(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[^\\w\\s]', '', s)  # [] Toda palavra ^nega√ß√£o \\w Letras, n√∫meros e underscore \\s espa√ßo\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    s = re.sub(r'^0+(\\d+)', r'\\1', s)\n",
    "    return s\n",
    "\n",
    "# Preprocessa todas as delegacias\n",
    "df_delegacias[\"DP_PREP\"] = df_delegacias[\"DP\"].astype(str).apply(preprocessar_string)\n",
    "\n",
    "def procura_similaridade(delegacia):\n",
    "    s = preprocessar_string(str(delegacia))\n",
    "    match = process.extractOne(\n",
    "        s,\n",
    "        df_delegacias[\"DP_PREP\"],\n",
    "        scorer=fuzz.ratio\n",
    "    )\n",
    "    if match and match[1] >= 90:\n",
    "        idx = df_delegacias[\"DP_PREP\"][df_delegacias[\"DP_PREP\"] == match[0]].index[0]\n",
    "        return df_delegacias.loc[idx, \"MUNICIPIO\"]\n",
    "    return np.nan\n",
    "\n",
    "# Aplica nos registros com cidade nula\n",
    "mascara = df[\"CIDADE\"].isna()\n",
    "df.loc[mascara, \"CIDADE\"] = df.loc[mascara, \"DELEGACIA_ELABORACAO\"].apply(procura_similaridade)\n",
    "\n",
    "print(\"Substitui√ß√µes conclu√≠das.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p> Ruidos de cidades com valor 2513851.0, que corresponde a cidade de Santo Andr√© </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"CIDADE\"] == \"2513851.0\", \"CIDADE\"] = \"Santo Andre\"\n",
    "\n",
    "df.to_csv('dados/SpSafe_2022.csv', index=False, sep=';', encoding='utf-8')\n",
    "print(\"Dados atualizados com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p> Algumas corre√ß√µes que faltaram  com  maiores repeti√ß√µes </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delegacias_agrupadas = df[df[\"CIDADE\"].isnull()][\"DELEGACIA_ELABORACAO\"].value_counts()\n",
    "delegacias_agrupadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for indice, linha in df[df[\"CIDADE\"].isnull()].iterrows():\n",
    "    if linha[\"DELEGACIA_ELABORACAO\"] == \"73 DP JACANA\":\n",
    "        df.at[indice, \"CIDADE\"] = \"S√£o Paulo\"\n",
    "    elif linha[\"DELEGACIA_ELABORACAO\"] == \"PLANTAO DE SOROCABA  Z NORTE\":\n",
    "        df.at[indice, \"CIDADE\"] = \"Sorocaba\"\n",
    "    elif linha[\"DELEGACIA_ELABORACAO\"] == \"CPJ RIBEIRAO PRETO\":\n",
    "        df.at[indice, \"CIDADE\"] = \"Ribeir√£o Preto\"\n",
    "    elif linha[\"DELEGACIA_ELABORACAO\"] == \"DELPOLPLANTAO SUMARE\":\n",
    "        df.at[indice, \"CIDADE\"] = \"Sumar√©\"\n",
    "    elif linha[\"DELEGACIA_ELABORACAO\"] == \"101 DP JDIM IMBUIAS\":\n",
    "        df.at[indice, \"CIDADE\"] = \"Jardim das Imbuias\"\n",
    "    elif linha[\"DELEGACIA_ELABORACAO\"] == \"89 DP JARDIM TABOAO\":\n",
    "        df.at[indice, \"CIDADE\"] = \"S√£o Paulo\"\n",
    "    elif linha[\"DELEGACIA_ELABORACAO\"] == \"DELSECFRANCA PLANTAO\":\n",
    "        df.at[indice, \"CIDADE\"] = \"Franca\"\n",
    "    elif linha[\"DELEGACIA_ELABORACAO\"] == \"DELSECITANHAEM PLANTAO\":\n",
    "        df.at[indice, \"CIDADE\"] = \"Itanha√©m\"\n",
    "    elif linha[\"DELEGACIA_ELABORACAO\"] == \"CPJ LINS\":\n",
    "        df.at[indice, \"CIDADE\"] = \"Lins\"\n",
    "    elif linha[\"DELEGACIA_ELABORACAO\"] == \"27 DP DR IGNACIO FRANCISCO\":\n",
    "        df.at[indice, \"CIDADE\"] = \"S√£o Paulo\"\n",
    "    elif linha[\"DELEGACIA_ELABORACAO\"] == \"DELSECRIO CLARO PLANTAO\":\n",
    "        df.at[indice, \"CIDADE\"] = \"Rio Claro\"\n",
    "\n",
    "print(\"Altera√ß√µes realizadas com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dados/SpSafe_2022.csv', index=False, sep=';', encoding='utf-8')\n",
    "print(\"Salvo com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<h2> Cruzamento de dados: SpSafe com os Dados demogr√°ficos</h2>\n",
    "<p> Cruzei os dados das cidades conseguidas a cima, com os dados demogr√°ficos do estado de S√£o Paulo via SEADE </p>\n",
    "<a href=\"https://repositorio.seade.gov.br/dataset/demografia\">Clique aqui para visitar o site</a>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malha_demografica = gpd.read_file(\"dados/Dados Demograficos/Den Demografica.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p> Algumas corre√ß√µes de cidades incorretas, e igualando padr√µes com os Dados Demogr√°ficos   </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CIDADE\"] = df[\"CIDADE\"].replace({\n",
    "    \"Jardim das Imbuias\": \"S√£o Paulo\",\n",
    "    \"Santa B√°rbara D'Oeste\" : \"Santa B√°rbara d'Oeste\",\n",
    "    \"√Åguas de Lindoia\" : \"√Åguas de Lind√≥ia\",\n",
    "    \"Pompeia\" : \"Pomp√©ia\", \n",
    "    \"Santa Rosa do Viterbo\" : \"Santa Rosa de Viterbo\",\n",
    "    \"Uch√¥a\" : \"Uchoa\",\n",
    "    \"Santo Andre\": \"Santo Andr√©\"\n",
    "})\n",
    "df.to_csv('dados/SpSafe_2022.csv', index=False, sep=';', encoding='utf-8')\n",
    "print(\"Altera√ß√µes feitas com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cidades = df[\"CIDADE\"].value_counts().reset_index()\n",
    "df_cidades.columns = [\"CIDADE\", \"QUANTIDADE_CRIMES\"]\n",
    "df_cidades[\"QUANTIDADE_POPULACAO\"] = 0\n",
    "\n",
    "for indice, linha in df_cidades.iterrows():\n",
    "    qtd = malha_demografica[malha_demografica[\"Nome\"].str.contains(linha[\"CIDADE\"], na=False)]\n",
    "\n",
    "    if not qtd.empty:\n",
    "        df_cidades.at[indice, \"QUANTIDADE_POPULACAO\"] = qtd.iloc[0][\"Pop\"]\n",
    "\n",
    "\n",
    "df_cidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantidade_crime = df_cidades[\"QUANTIDADE_CRIMES\"].sum()\n",
    "quantidade_pessoas = df_cidades[\"QUANTIDADE_POPULACAO\"].sum()\n",
    "media_estadual = round(quantidade_crime / quantidade_pessoas * 100000)\n",
    "\n",
    "\n",
    "print(f\"Quantidade crime {quantidade_crime}, Quantidade pessoas {quantidade_pessoas}\")\n",
    "\n",
    "print(f\"A m√©dia estadual √© de {media_estadual} crimes a cada 100 mil habitantes. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cidades[\"CRIMES_POR_100K\"] = round((df_cidades[\"QUANTIDADE_CRIMES\"] / df_cidades[\"QUANTIDADE_POPULACAO\"]) * 100000)\n",
    "print(\"Dados calculados com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cidades_filtrado = df_cidades.loc[(df_cidades.QUANTIDADE_POPULACAO > 0 ) & (df_cidades.QUANTIDADE_POPULACAO < 50000 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cidades_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tamanho do gr√°fico\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Scatter plot\n",
    "plt.scatter(df_cidades_filtrado[\"QUANTIDADE_POPULACAO\"], df_cidades_filtrado[\"CRIMES_POR_100K\"], color='dodgerblue', alpha=0.7)\n",
    "\n",
    "# Linha horizontal com a m√©dia\n",
    "plt.axhline(y=media_estadual, color='red', linestyle='--', label=f'M√©dia estadual: {media_estadual:.2f}')\n",
    "\n",
    "# Labels e t√≠tulo\n",
    "plt.xlabel(\"Popula√ß√£o\")\n",
    "plt.ylabel(\"Crimes por 100 mil habitantes\")\n",
    "plt.title(\"Rela√ß√£o entre Media de crimes em cidades com popula√ß√£o menor que 50k com a estadual\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p> Tabela com os dados do gr√°fico acima.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cidades_filtrado.loc[df_cidades_filtrado.CRIMES_POR_100K > 1431]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<h2> Tratamento de BO's Duplicados</h2>\n",
    "<p> </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: left;\">\n",
    "<p> Definindo de quais ser√£o considerados como BO's Duplicados, a partir de uma lista de parametros contendo as colunas (campos) que ser√£o utilizadas para a defini√ß√£o de um filtro. \n",
    "\n",
    "Utilizar somente o campo 'NUM_BO' n√£o √© interssante,pois apenas considerando tal campo se tem uma maior probabilidade de exclus√£o de dados n√£o duplicados. J√° que com este pensamento n√£o √© levado em conta a possibilidade de erros de digita√ß√£o ou outros possiveis erros dos quais no final resultariam na exclus√£o de dados n√£o duplicados, e sim dados que precisam, somente, de um tratamento.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_duplicados = ['NUM_BO','NATUREZA_APURADA' ,'CODIGO_BOLETIM', 'LOCAL_ELABORACAO','TIPO_LOCAL']\n",
    "\n",
    "# Identifica duplicatas (mantendo o primeiro como \"n√£o duplicado\")\n",
    "duplicados = df.duplicated(subset=param_duplicados, keep='first')\n",
    "\n",
    "# Exibe os duplicados\n",
    "df_duplicados = df[duplicados]\n",
    "df_duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<h3> Remo√ß√£o dos dados duplicados do Dataframe:</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove os duplicados do DataFrame original\n",
    "df_sem_duplicados = df[~duplicados]\n",
    "df = df[~duplicados]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p>Calculo de m√©dia estadual de crimes por 100 mil habitantes.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantidade_crime = df_cidades[\"QUANTIDADE_CRIMES\"].sum()\n",
    "quantidade_pessoas = df_cidades[\"QUANTIDADE_POPULACAO\"].sum()\n",
    "media_estadual = round(quantidade_crime / quantidade_pessoas * 100000)\n",
    "\n",
    "\n",
    "print(f\"Quantidade crime {quantidade_crime}, Quantidade pessoas {quantidade_pessoas}\")\n",
    "\n",
    "print(f\"A m√©dia estadual √© de {media_estadual} crimes a cada 100 mil habitantes. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cidades[\"CRIMES_POR_100K\"] = round((df_cidades[\"QUANTIDADE_CRIMES\"] / df_cidades[\"QUANTIDADE_POPULACAO\"]) * 100000)\n",
    "print(\"Dados calculados com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p>Cidades com menos de 50.0000 habitantes.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cidades_filtrado = df_cidades.loc[(df_cidades.QUANTIDADE_POPULACAO > 0 ) & (df_cidades.QUANTIDADE_POPULACAO < 50000 )]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p>Gr√°fico de dispers√£o das cidades com popula√ß√£o menor de 50k, comparando a taxa de crime por 100k pessoas, com a m√©dia estadual</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cidades_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tamanho do gr√°fico\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Scatter plot\n",
    "plt.scatter(df_cidades_filtrado[\"QUANTIDADE_POPULACAO\"], df_cidades_filtrado[\"CRIMES_POR_100K\"], color='dodgerblue', alpha=0.7)\n",
    "\n",
    "# Linha horizontal com a m√©dia\n",
    "plt.axhline(y=media_estadual, color='red', linestyle='--', label=f'M√©dia estadual: {media_estadual:.2f}')\n",
    "\n",
    "# Labels e t√≠tulo\n",
    "plt.xlabel(\"Popula√ß√£o\")\n",
    "plt.ylabel(\"Crimes por 100 mil habitantes\")\n",
    "plt.title(\"Rela√ß√£o entre Media de crimes em cidades com popula√ß√£o menor que 50k com a estadual\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p>Tabela com as cidades;</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cidades_filtrado.loc[df_cidades_filtrado.CRIMES_POR_100K > 1431]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<h3> Quantidade de BO's por dia na semana</h3>\n",
    "</div>\n",
    "\n",
    "<div style = \"text-align: left;\">\n",
    "<p> Interesse em em entender quais dias da semana, e sua propor√ß√£o, acontecem maior quantidade de crimes, a partir da quantidade de BO's registrados. Assim, podendo inferir em quais dias s√£o mais prov√°veis que ocorra crimes, junto de sua propro√ß√£o, no estado de S√£o Paulo.</p> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dias = [\"Segunda\", \"Ter√ßa\", \"Quarta\", \"Quinta\", \"Sexta\", \"S√°bado\", \"Domingo\"]\n",
    "crimes = [0] * 7\n",
    "dias_semana = [\"SEGUNDA-FEIRA\", \"TER√áA-FEIRA\", \"QUARTA-FEIRA\", \"QUINTA-FEIRA\", \"SEXTA-FEIRA\", \"S√ÅBADO\", \"DOMINGO\"]\n",
    "\n",
    "for i, dia in enumerate(dias_semana):\n",
    "    crimes[i] = df.loc[\n",
    "        (df['DIA_SEMANA'] == dia)\n",
    "    ].shape[0]\n",
    "\n",
    "media = sum(crimes) / len(crimes)\n",
    "\n",
    "\n",
    "# Gr√°fico\n",
    "plt.figure(figsize=(12, 6))\n",
    "cores = plt.cm.viridis([i / 6 for i in range(7)])\n",
    "barras = plt.bar(dias, crimes, color=cores)\n",
    "\n",
    "plt.xlabel(\"Dias da Semana\", fontsize=14)\n",
    "plt.ylabel(\"Quantidade de BO's\", fontsize=14)\n",
    "plt.title(\"Quantidade de BO's por dia na semana\", fontsize=16, weight='bold')\n",
    "\n",
    "for barra in barras:\n",
    "    altura = barra.get_height()\n",
    "    plt.text(barra.get_x() + barra.get_width()/2., altura + 0.5,\n",
    "             f'{int(altura)}', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "# Linha da m√©dia\n",
    "plt.axhline(media, color='red', linestyle='--', linewidth=2, label=f'M√©dia: {media:.1f}')\n",
    "plt.text(len(dias) - 0.5, media + 0.5, f'', color='red', fontsize=12)\n",
    "\n",
    "# Grade, legenda e layout\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<h3> Rela√ß√£o quantidades BO's com periodo do Dia</h3>\n",
    "</div>\n",
    "\n",
    "<div style = \"text-align: left;\">\n",
    "<p> Com os dados sobre a quantidade de B.O.s registrados por dia da semana, tornou-se interessante tamb√©m identificar os per√≠odos com maior incid√™ncia de crimes, ou seja, os momentos em que h√° mais registros de B.O.s. Dessa forma, buscou-se correlacionar a quantidade de B.O.s com o per√≠odo em que os crimes ocorreram, permitindo uma an√°lise mais precisa dos momentos de maior criminalidade.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mapeamento dos per√≠odos\n",
    "periodo_mapeamento = {\n",
    "    'PELA MANHA': 'Manh√£',\n",
    "    'A TARDE': 'Tarde',\n",
    "    'A NOITE': 'Noite',\n",
    "    'DE MADRUGADA': 'Madrugada',\n",
    "    'EM HORA INCERTA': 'Incerto'\n",
    "}\n",
    "\n",
    "# Aplica o mapeamento para uma nova coluna\n",
    "df['PERIODO_SIMPLIFICADO'] = df['PERIODO_OCORRENCIA'].map(periodo_mapeamento)\n",
    "\n",
    "# Per√≠odos simplificados na ordem desejada\n",
    "periodos = [\"Manh√£\", \"Tarde\", \"Noite\", \"Madrugada\", \"Incerto\"]\n",
    "qnt_BO = []\n",
    "\n",
    "# Contagem de BOs por per√≠odo\n",
    "for periodo in periodos:\n",
    "    contagem = df[df['PERIODO_SIMPLIFICADO'] == periodo].shape[0]\n",
    "    qnt_BO.append(contagem)\n",
    "\n",
    "# C√°lculo da m√©dia\n",
    "media = sum(qnt_BO) / len(qnt_BO)\n",
    "\n",
    "# Gr√°fico\n",
    "plt.figure(figsize=(12, 6))\n",
    "barras = plt.bar(periodos, qnt_BO)\n",
    "\n",
    "# Labels e t√≠tulo\n",
    "plt.xlabel(\"Per√≠odos\", fontsize=14)\n",
    "plt.ylabel(\"Quantidade de BO's\", fontsize=14)\n",
    "plt.title(\"Quantidade de BO's por Per√≠odo do Dia\", fontsize=16, weight='bold')\n",
    "\n",
    "# Adiciona os valores em cima de cada barra\n",
    "for barra in barras:\n",
    "    altura = barra.get_height()\n",
    "    plt.text(barra.get_x() + barra.get_width()/2., altura + 0.5,\n",
    "             f'{int(altura)}', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "# Linha da m√©dia\n",
    "plt.axhline(media, color='red', linestyle='--', linewidth=2, label=f'M√©dia: {media:.1f}')\n",
    "plt.text(len(periodos) - 0.5, media + 1, f'', color='red', fontsize=12)\n",
    "\n",
    "# Grade, legenda e layout\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<h3> Dias da semana t√™m maior incid√™ncia de invas√µes domiciliares (Pergunta 8)</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: left;\">\n",
    "<p> Necessidade dee criar uma lista de tipos de crimes que podem ser relacionados com invas√£o domiciliar para que tenha se uma maior amostragem de dados que se encaxem com invas√£o domiciliar.\n",
    "\n",
    "Por√©m, a amostragem teve uma pequena quantidade de dados, mesmo utilizando a lista de tipos de crimes. Outro ponto para observa√ß√£o √© pelo fato de serem crimes relacionados h√° a possibilidade de n√£o refletir com uma boa acur√°cia (ru√≠do) a resposta da pergunta</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_invasao_domiciliar = [\n",
    "    'VIOLACAO DE DOMICILIO (ART. 150)',\n",
    "    'FURTO (ART. 155) - RESIDENCIA',\n",
    "    'FURTO QUALIFICADO (ART. 155, ¬ß4O.) - RESIDENCIA',\n",
    "    'A.I.-FURTO (ART. 155) - RESIDENCIA',\n",
    "    'A.I.-FURTO QUALIFICADO (ART. 155, ¬ß4O.) - RESIDENCIA',\n",
    "    'FURTO DE COISA COMUM (ART. 156) - RESIDENCIA',\n",
    "    'ROUBO (ART. 157) - RESIDENCIA'\n",
    "]\n",
    "\n",
    "df[df['NATUREZA_APURADA'].isin(crimes_invasao_domiciliar)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<h3> Gera√ß√£o do Gr√°fico</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dados\n",
    "dias = [\"Segunda\", \"Ter√ßa\", \"Quarta\", \"Quinta\", \"Sexta\", \"S√°bado\", \"Domingo\"]\n",
    "invasoes = [0] * 7\n",
    "dias_semana = [\"SEGUNDA-FEIRA\", \"TER√áA-FEIRA\", \"QUARTA-FEIRA\", \"QUINTA-FEIRA\", \"SEXTA-FEIRA\", \"S√ÅBADO\", \"DOMINGO\"]\n",
    "\n",
    "for i, dia in enumerate(dias_semana):\n",
    "    invasoes[i] = df.loc[\n",
    "        (df['DIA_SEMANA'] == dia) & (df['NATUREZA_APURADA'].isin(crimes_invasao_domiciliar))\n",
    "    ].shape[0]\n",
    "\n",
    "# C√°lculo da m√©dia\n",
    "media = sum(invasoes) / len(invasoes)\n",
    "\n",
    "\n",
    "# Gr√°fico\n",
    "plt.figure(figsize=(12, 6))\n",
    "cores = plt.cm.viridis([i / 6 for i in range(7)])\n",
    "barras = plt.bar(dias, invasoes, color=cores)\n",
    "\n",
    "# Labels e t√≠tulo\n",
    "plt.xlabel(\"Dias da Semana\", fontsize=14)\n",
    "plt.ylabel(\"Invas√µes Domiciliares\", fontsize=14)\n",
    "plt.title(\"Invas√µes Domiciliares por Dia da Semana\", fontsize=16, weight='bold')\n",
    "\n",
    "# Adiciona os valores em cima de cada barra\n",
    "for barra in barras:\n",
    "    altura = barra.get_height()\n",
    "    plt.text(barra.get_x() + barra.get_width()/2., altura + 0.5,\n",
    "             f'{int(altura)}', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "# Linha da m√©dia\n",
    "plt.axhline(media, color='red', linestyle='--', linewidth=2, label=f'M√©dia: {media:.1f}')\n",
    "plt.text(len(dias) - 0.5, media + 0.5, f'', color='red', fontsize=12)\n",
    "\n",
    "# Grade, legenda e layout\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fatores Sociodemogr√°ficos\n",
    "An√°lise: COR DA PELE X CRIME COMETIDO\n",
    "* Existe alguma correla√ß√£o entre esses dois fatores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*An√°lise feita por: Matheus Kauan*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa an√°lise, ser√£o gerados alguns gr√°ficos para melhor entendimento, mas antees √© necess√°rio realizar algumas filtragens e an√°lise dos dados do dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtragem do dataframe para sele√ß√£o de crimes que est√£o relacionados a viol√™ncia f√≠sica/verbal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_violencia_fisica_verbal = [\n",
    "    'LESAO CORPORAL (ART. 129)',\n",
    "    'LESAO CORPORAL CULPOSA NA DIRECAO DE VEICULO AUTOMOTOR (ART. 303)',\n",
    "    'LESAO CORPORAL SEGUIDA DE MORTE',\n",
    "    'AMEACA (ART. 147)',\n",
    "    'INJURIA (ART. 140)',\n",
    "    'CALUNIA (ART. 138)',\n",
    "    'DESACATO (ART. 331)',\n",
    "    'RESISTENCIA (ART. 329)',\n",
    "    'VIOLENCIA DOMESTICA',\n",
    "    'HOMICIDIO DOLOSO',\n",
    "    'LATROCINIO',\n",
    "    'MORTE DECORRENTE DE INTERVENCAO POLICIAL'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando um novo dataframe com a filtragem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_violencia_f_v = df[df['NATUREZA_APURADA'].isin(crimes_violencia_fisica_verbal)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quantidade de crimes por natureza\n",
    "print(df_violencia_f_v['NATUREZA_APURADA'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar apenas os registros onde 'COR_PELE' n√£o √© nulo\n",
    "df_violencia_f_v = df_violencia_f_v[df_violencia_f_v['COR_PELE'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_violencia_f_v['COR_PELE'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando a porcentagem de dados que s√£o nulos da coluna 'COR_PELE' em rela√ß√£o ao total de linhas (dados):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N√∫mero de valores NaN na coluna\n",
    "num_nan = df['COR_PELE'].isna().sum()\n",
    "\n",
    "# N√∫mero total de linhas\n",
    "total_linhas = len(df)\n",
    "\n",
    "# Porcentagem de NaN\n",
    "porcentagem_nan = (num_nan / total_linhas) * 100\n",
    "\n",
    "print(f'Porcentagem de NaN em COR_PELE: {porcentagem_nan:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmando a veracidade da porcentagem acima:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar onde COR_PELE √© nulo\n",
    "cor_pele_nulo = df[df['COR_PELE'].isna()]\n",
    "\n",
    "# Mostrar o dataframe filtrado\n",
    "print(cor_pele_nulo)\n",
    "\n",
    "# Mostrar a quantidade de linhas\n",
    "print(f'Total de linhas com COR_PELE nulo: {len(cor_pele_nulo)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar onde COR_PELE n√£o √© nulo\n",
    "cor_pele_preenchido = df[df['COR_PELE'].notna()]\n",
    "\n",
    "# Mostrar o dataframe filtrado\n",
    "print(cor_pele_preenchido)\n",
    "\n",
    "# Mostrar a quantidade de linhas\n",
    "print(f'Total de linhas com COR_PELE preenchido: {len(cor_pele_preenchido)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui encontramos um grande problema: mais de 97% dos dados est√£o nulos na coluna COR_PELE. Assim, os gr√°ficos ser√£o gerados com base em apenas 3% dos registros que possuem informa√ß√µes sobre a cor da pele da v√≠tima, o que representa um obst√°culo para a veracidade e a representatividade das informa√ß√µes que podem ser extra√≠das dos gr√°ficos a priori."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria√ß√£o de um gr√°fico de barras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sns.countplot(data=df_violencia_f_v, x='COR_PELE', hue='NATUREZA_APURADA')\n",
    "plt.title('Frequ√™ncia de Crimes por Cor da Pele da V√≠tima (Baseado em 3% dos dados)')\n",
    "plt.xlabel('Cor da Pele')\n",
    "plt.ylabel('Quantidade de Casos')\n",
    "plt.legend(title='Tipo de Crime')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar crimes √∫nicos onde COR_PELE n√£o √© nulo\n",
    "crimes_unicos = df_violencia_f_v['NATUREZA_APURADA'].unique()\n",
    "\n",
    "print(crimes_unicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gerando um HeatMap para visualizar a rela√ß√£o entre COR_PELE e NATUREZA_APURADA\n",
    "\n",
    "pivot = df_violencia_f_v.pivot_table(index='COR_PELE', columns='NATUREZA_APURADA', aggfunc='size', fill_value=0)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(pivot, annot=True, fmt='d', cmap='Reds')\n",
    "plt.title('Distribui√ß√£o de Crimes Verbais/F√≠sicos por Cor da Pele')\n",
    "plt.xlabel('Tipo de Crime')\n",
    "plt.ylabel('Cor da Pele')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <h2>Explorando os dados: datas dos BOs</h2>\n",
    "  <p>Para entender a natureza dos dias dos acontecimentos e a correla√ß√£o com datas espec√≠ficas, cruzaremos os dados de datas at√≠picas e datas dos crimes. Para realizar esta anlise mais apurada, dividimos os dados em \"Natal\", \"Carnaval\", \"Demais Feriados\", \"Jogos de futebol\" e \"Dias comuns\".</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir as categorias baseadas na sua lista eventos_sp_2022\n",
    "carnaval = ['2022-02-28', '2022-03-01', '2022-03-02']  # Carnaval + Quarta de Cinzas\n",
    "natal = ['2022-12-24', '2022-12-25', '2022-12-31']     # Natal + V√©speras\n",
    "\n",
    "outros_feriados = [\n",
    "    '2022-01-01', '2022-04-15', '2022-04-21', '2022-05-01',\n",
    "    '2022-06-16', '2022-07-09', '2022-09-07', '2022-10-12',\n",
    "    '2022-10-28', '2022-11-02', '2022-11-15'\n",
    "]\n",
    "\n",
    "jogos_futebol = [\n",
    "    '2022-01-25', '2022-03-10', '2022-03-30', '2022-04-03',\n",
    "    '2022-05-02', '2022-05-22', '2022-06-20', '2022-08-21',\n",
    "    '2022-09-11', '2022-10-16', '2022-11-24', '2022-11-28',\n",
    "    '2022-12-02', '2022-12-05', '2022-12-09',  # j√° existentes\n",
    "\n",
    "    # Novas datas que n√£o estavam no array original\n",
    "    '2022-01-30', '2022-02-02', '2022-02-06', '2022-02-17', '2022-02-19',\n",
    "    '2022-02-20', '2022-02-21', '2022-02-25', '2022-03-17', '2022-03-19',\n",
    "    '2022-03-20', '2022-04-17', '2022-05-06', '2022-06-19', '2022-07-30',\n",
    "    '2022-08-06', '2022-09-10', '2022-10-23', '2022-11-12', '2022-12-03'\n",
    "]\n",
    "\n",
    "\n",
    "# Fun√ß√£o de categoriza√ß√£o (ajustada para lidar com strings e datetime)\n",
    "def categorizar_evento(data):\n",
    "    if pd.isna(data):  # Tratar valores nulos\n",
    "        return 'DIA NORMAL'\n",
    "    \n",
    "    data_str = data.strftime('%Y-%m-%d') if hasattr(data, 'strftime') else str(data)[:10]  # Adapta para datetime ou string\n",
    "    if data_str in carnaval:\n",
    "        return 'CARNAVAL'\n",
    "    elif data_str in natal:\n",
    "        return 'NATAL'\n",
    "    elif data_str in outros_feriados:\n",
    "        return 'OUTROS FERIADOS'\n",
    "    elif data_str in jogos_futebol:\n",
    "        return 'JOGOS FUTEBOL'\n",
    "    else:\n",
    "        return 'DIA NORMAL'\n",
    "\n",
    "# Aplicar a categoriza√ß√£o\n",
    "df['DATA_OCORRENCIA'] = pd.to_datetime(df['DATA_OCORRENCIA'], errors='coerce')  # Garante datetime e trata erros\n",
    "df['CATEGORIA_EVENTO'] = df['DATA_OCORRENCIA'].apply(categorizar_evento)\n",
    "\n",
    "# Verificar contagem\n",
    "print(df['CATEGORIA_EVENTO'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p>Agora, vamos comparar a m√©dia di√°ria de crimes para cada categoria:</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular dias √∫nicos por categoria\n",
    "dias_por_categoria = {\n",
    "    'CARNAVAL': len(carnaval),\n",
    "    'NATAL': len(natal),\n",
    "    'OUTROS FERIADOS': len(outros_feriados),\n",
    "    'JOGOS FUTEBOL': len(jogos_futebol),\n",
    "    'DIA NORMAL': len(df['DATA_OCORRENCIA'].dt.date.unique()) - (len(carnaval) + len(natal) + len(outros_feriados) + len(jogos_futebol))\n",
    "}\n",
    "\n",
    "# Calcular m√©dia di√°ria\n",
    "crimes_por_categoria = df.groupby('CATEGORIA_EVENTO').size().reset_index(name='TOTAL_CRIMES')\n",
    "crimes_por_categoria['MEDIA_DIARIA'] = crimes_por_categoria['TOTAL_CRIMES'] / crimes_por_categoria['CATEGORIA_EVENTO'].map(dias_por_categoria)\n",
    "\n",
    "# Filtrar apenas eventos (excluindo dias normais)\n",
    "crimes_analise = crimes_por_categoria[crimes_por_categoria['CATEGORIA_EVENTO'] != 'DIA NORMAL']\n",
    "\n",
    "# Configura√ß√µes de estilo (opcional)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Cores tem√°ticas para cada categoria\n",
    "colors = {\n",
    "    'CARNAVAL': '#FF69B4',  # Rosa\n",
    "    'NATAL': '#32CD32',     # Verde\n",
    "    'OUTROS FERIADOS': '#FFA500',  # Laranja\n",
    "    'JOGOS FUTEBOL': '#1E90FF'     # Azul\n",
    "}\n",
    "\n",
    "# Criar o gr√°fico de barras\n",
    "bars = plt.bar(\n",
    "    crimes_analise['CATEGORIA_EVENTO'], \n",
    "    crimes_analise['MEDIA_DIARIA'],\n",
    "    color=[colors[cat] for cat in crimes_analise['CATEGORIA_EVENTO']]\n",
    ")\n",
    "\n",
    "# Linha de refer√™ncia (m√©dia di√°ria normal)\n",
    "media_normal = crimes_por_categoria.loc[crimes_por_categoria['CATEGORIA_EVENTO'] == 'DIA NORMAL', 'MEDIA_DIARIA'].values[0]\n",
    "plt.axhline(\n",
    "    media_normal, \n",
    "    color='red', \n",
    "    linestyle='--', \n",
    "    linewidth=2,\n",
    "    label=f'M√©dia dias normais: {media_normal:.1f}'\n",
    ")\n",
    "\n",
    "# Detalhes do gr√°fico\n",
    "plt.title('M√©dia Di√°ria de Crimes por Categoria de Evento\\nS√£o Paulo - 2022', fontsize=14, pad=20)\n",
    "plt.xlabel('Categoria do Evento', fontsize=12)\n",
    "plt.ylabel('M√©dia de Crimes por Dia', fontsize=12)\n",
    "plt.xticks(fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.legend(fontsize=11)\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width()/2, \n",
    "        height + 5,  # Offset para posicionar acima da barra\n",
    "        f'{height:.1f}', \n",
    "        ha='center', \n",
    "        va='bottom',\n",
    "        fontsize=10\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align: center;\">\n",
    "<p>Para uma vis√£o mais detalhada, podemos plotar a quantidade de crimes ao longo do ano, destacando os dias at√≠picos:</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Agrupar crimes por data\n",
    "crimes_por_data = df.groupby('DATA_OCORRENCIA').size().reset_index(name='TOTAL_CRIMES')\n",
    "\n",
    "# Identificar dias at√≠picos no DataFrame\n",
    "crimes_por_data['DIA_ATIPICO'] = crimes_por_data['DATA_OCORRENCIA'].isin(eventos_dates)\n",
    "\n",
    "# Configurar o gr√°fico\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Gr√°fico de linha principal\n",
    "plt.plot(crimes_por_data['DATA_OCORRENCIA'], \n",
    "         crimes_por_data['TOTAL_CRIMES'], \n",
    "         label='Crimes por dia', \n",
    "         color='gray', \n",
    "         alpha=0.6,\n",
    "         linewidth=1)\n",
    "\n",
    "# Destacar dias at√≠picos\n",
    "dias_atipicos = crimes_por_data[crimes_por_data['DIA_ATIPICO'] == True]\n",
    "plt.scatter(dias_atipicos['DATA_OCORRENCIA'], \n",
    "            dias_atipicos['TOTAL_CRIMES'], \n",
    "            color='red', \n",
    "            label='Dias at√≠picos', \n",
    "            zorder=5,\n",
    "            s=50)  # tamanho dos pontos\n",
    "\n",
    "# Configurar limites do eixo x para 2022\n",
    "plt.xlim([pd.to_datetime('2022-01-01'), pd.to_datetime('2022-12-31')])\n",
    "\n",
    "# Formatar eixo x para mostrar meses\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b'))  # Nomes curtos dos meses\n",
    "\n",
    "# Adicionar detalhes\n",
    "plt.xlabel('Data (2022)', fontsize=12)\n",
    "plt.ylabel('Quantidade de Crimes', fontsize=12)\n",
    "plt.title('Flutua√ß√£o Di√°ria de Crimes em S√£o Paulo (2022)\\nDias At√≠picos Destacados', fontsize=14, pad=20)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(linestyle='--', alpha=0.4)\n",
    "\n",
    "# Melhorar a legibilidade das datas\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <h2>BOs Iniciados X BOs Emitidos</h2>\n",
    "  <p>Para entender se todos os boletins de ocorr√™ncia de fato s√£o emitidos, ou pelo menos uma boa parte, cruzaremos os dados de BO_EMITIDOS e BO_INICIADOS. Tamb√™m observaremos para quais naturezas de crimes os boletins s√£o mais efeivado e para quais s√£o menos efetivados.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando os tipos de crimes:\n",
    "\n",
    "if 'NATUREZA_APURADA' in df.columns:\n",
    "    valores_unicos = df['NATUREZA_APURADA'].dropna().unique()\n",
    "    print(f\"Total de tipos √∫nicos: {len(valores_unicos)}\\n\")\n",
    "    print(\"Exemplos de tipos de natureza apurada:\")\n",
    "    for valor in sorted(valores_unicos)[:50]:  # Mostra os 50 primeiros para n√£o ficar gigante\n",
    "        print(f\"- {valor}\")\n",
    "else:\n",
    "    print(\"A coluna 'NATUREZA_APURADA' n√£o foi encontrada no dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Identificar os 6 tipos mais comuns\n",
    "top_6_crimes = df['NATUREZA_APURADA'].value_counts().head(6).index.tolist()\n",
    "\n",
    "# 2. Fun√ß√£o de categoriza√ß√£o\n",
    "def categorizar_crime(natureza):\n",
    "    natureza = str(natureza).upper()\n",
    "    \n",
    "    # Verificar os 6 tipos mais comuns\n",
    "    for crime in top_6_crimes:\n",
    "        if str(crime).upper() in natureza:\n",
    "            return crime.split('-')[-1].split('(')[0].strip()\n",
    "    \n",
    "    # Categorias espec√≠ficas\n",
    "    if 'FURTO' in natureza:\n",
    "        return 'FURTO'\n",
    "    elif 'ROUBO' in natureza:\n",
    "        return 'ROUBO'\n",
    "    elif 'HOMIC√çDIO' in natureza or 'HOMICIDIO' in natureza:\n",
    "        return 'HOMIC√çDIO'\n",
    "    elif 'LES√ÉO' in natureza or 'LESAO' in natureza:\n",
    "        return 'LES√ÉO CORPORAL'\n",
    "    elif 'ESTELIONATO' in natureza:\n",
    "        return 'ESTELIONATO'\n",
    "    elif 'TR√ÅFICO' in natureza or 'TRAFICO' in natureza:\n",
    "        return 'TR√ÅFICO DE DROGAS'\n",
    "    else:\n",
    "        return 'OUTROS'\n",
    "\n",
    "# 3. Aplicar categoriza√ß√£o e calcular status\n",
    "df['CATEGORIA_CRIME'] = df['NATUREZA_APURADA'].apply(categorizar_crime)\n",
    "df['STATUS_EMISSAO'] = df['BO_EMITIDO'].apply(lambda x: 'Emitido' if pd.notnull(x) else 'N√£o Emitido')\n",
    "\n",
    "# 4. Calcular estat√≠sticas por categoria\n",
    "emissoes_por_categoria = df.groupby('CATEGORIA_CRIME').agg(\n",
    "    Total_Iniciados=('STATUS_EMISSAO', 'count'),\n",
    "    Total_Emitidos=('STATUS_EMISSAO', lambda x: (x == 'Emitido').sum())\n",
    ").reset_index()\n",
    "\n",
    "emissoes_por_categoria['Perc_Emitidos'] = (emissoes_por_categoria['Total_Emitidos'] / \n",
    "                                          emissoes_por_categoria['Total_Iniciados']) * 100\n",
    "\n",
    "# Ordenar por porcentagem de emiss√£o\n",
    "emissoes_por_categoria = emissoes_por_categoria.sort_values('Perc_Emitidos', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar gr√°fico de barras\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Paleta de cores - usando as 6 cores principais + cinza para \"OUTROS\"\n",
    "cores = sns.color_palette(\"viridis\", n_colors=6) + [(0.7, 0.7, 0.7)]\n",
    "cores = cores[:len(emissoes_por_categoria)]  # Ajustar para o n√∫mero real de categorias\n",
    "\n",
    "ax = sns.barplot(\n",
    "    data=emissoes_por_categoria,\n",
    "    x='CATEGORIA_CRIME',\n",
    "    y='Perc_Emitidos',\n",
    "    palette=cores,\n",
    "    order=emissoes_por_categoria['CATEGORIA_CRIME']  # Manter a ordena√ß√£o\n",
    ")\n",
    "\n",
    "# Adicionar r√≥tulos de porcentagem\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x() + p.get_width()/2.,\n",
    "            height + 0.5,\n",
    "            f'{height:.1f}%',\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            fontsize=10)\n",
    "\n",
    "# Linha de m√©dia geral\n",
    "media_geral = (df['STATUS_EMISSAO'] == 'Emitido').mean() * 100\n",
    "ax.axhline(media_geral, color='red', linestyle='--', linewidth=1.5)\n",
    "ax.text(len(emissoes_por_categoria)-0.8, media_geral+2, \n",
    "        f'M√©dia Geral: {media_geral:.1f}%', \n",
    "        color='red',\n",
    "        fontsize=11,\n",
    "        bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "# Adicionar volume de ocorr√™ncias\n",
    "for i, row in emissoes_por_categoria.iterrows():\n",
    "    ax.text(i, -3, \n",
    "            f\"N={row['Total_Iniciados']:,}\", \n",
    "            ha='center', \n",
    "            va='top', \n",
    "            rotation=45, \n",
    "            fontsize=9,\n",
    "            color='dimgrey')\n",
    "\n",
    "# Configura√ß√µes do gr√°fico\n",
    "plt.title('Taxa de Emiss√£o de BOs por Categoria de Crime\\n(Top 6 Tipos Mais Comuns + Outros)', \n",
    "          fontsize=15, pad=20)\n",
    "plt.xlabel('Categoria de Crime', fontsize=12)\n",
    "plt.ylabel('BOs Emitidos (%)', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.ylim(0, 105)  # Espa√ßo extra para os r√≥tulos\n",
    "\n",
    "# Ajustar layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <h2>Explorando os dados: Tipologia vi√°ria</h2>\n",
    "  <p>Em quais vias acontecem maior n√∫mero de crimes? Visando verificar se os dados nos respondem esta pergunta, observaremos aqui a correla√ß√£o entre o n√∫mero de crimes e os locais onde aconteceram. Para isso, vamos dividir os dados de LOGRADOURO em: Rua, Avenida, nulo, Rodovia e outros que consite em: Estrada, Pra√ßa, Alameda e Travessa; e ap√≥s isso sr√° possivel verificar onde mais acontecem crimes</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para classificar o tipo de logradouro\n",
    "def classificar_logradouro(log):\n",
    "    if pd.isna(log):\n",
    "        return 'NULO'\n",
    "    log = log.strip().lower()\n",
    "    if log.startswith('rua'):\n",
    "        return 'Rua'\n",
    "    elif log.startswith('avenida') or log.startswith('av.'):\n",
    "        return 'Avenida'\n",
    "    elif any(log.startswith(tipo) for tipo in ['pra√ßa', 'praca', 'travessa', 'trv.', 'estrada', 'alameda']):\n",
    "        return 'OUTROS'\n",
    "    elif log.startswith('rodovia'):\n",
    "        return 'Rodovia'\n",
    "    else:\n",
    "        return 'OUTROS'\n",
    "\n",
    "# Aplica classifica√ß√£o\n",
    "df['TIPO_LOGRADOURO'] = df['LOGRADOURO'].apply(classificar_logradouro)\n",
    "\n",
    "# Contagem por tipo\n",
    "contagem_logradouros = df['TIPO_LOGRADOURO'].value_counts().reset_index()\n",
    "contagem_logradouros.columns = ['Tipo de Logradouro', 'Quantidade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Criar gr√°fico de pizza simples\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(contagem_logradouros['Quantidade'],\n",
    "        labels=contagem_logradouros['Tipo de Logradouro'],\n",
    "        autopct='%1.1f%%',\n",
    "        startangle=90,\n",
    "        colors=plt.cm.Pastel1.colors,\n",
    "        wedgeprops={'linewidth': 1, 'edgecolor': 'white'})\n",
    "\n",
    "# Adicionar t√≠tulo\n",
    "plt.title('Distribui√ß√£o de Crimes por Tipo de Logradouro', pad=20)\n",
    "\n",
    "# Mostrar o gr√°fico\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <h2>Crimes em datas de jogos: Infer√™ncia est√°tistica</h2>\n",
    "  An√°lise por Arthur Teodoro\n",
    "  <p>Como j√° foi observado, as medias de crimes registradas se demonstraram bem mais altas em dias \"fora do comum\", como feriados e dias de jogos. Visando provar que h√° rela√ß√£o entre quantidade de crimes e eventos atip√≠cos, faremos aqui demonstra√ß√µes gr√°ficas e marem√°ticas que provem o ponto. \n",
    "  \n",
    "  Observe o gr√°fico a seguir:</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar os dados para dias normais e dias de jogos\n",
    "df_normal = df[df['CATEGORIA_EVENTO'] == 'DIA NORMAL']\n",
    "df_futebol = df[df['CATEGORIA_EVENTO'] == 'JOGOS FUTEBOL']\n",
    "\n",
    "# Contar n√∫mero de dias √∫nicos por dia da semana (necess√°rio para calcular m√©dia)\n",
    "dias_unicos_normal = df_normal[['DATA_OCORRENCIA', 'DIA_SEMANA']].drop_duplicates()\n",
    "dias_unicos_futebol = df_futebol[['DATA_OCORRENCIA', 'DIA_SEMANA']].drop_duplicates()\n",
    "\n",
    "# Contar crimes por dia da semana\n",
    "crimes_normal = df_normal.groupby('DIA_SEMANA').size()\n",
    "crimes_futebol = df_futebol.groupby('DIA_SEMANA').size()\n",
    "\n",
    "# Contar dias √∫nicos por dia da semana\n",
    "contagem_dias_normal = dias_unicos_normal['DIA_SEMANA'].value_counts()\n",
    "contagem_dias_futebol = dias_unicos_futebol['DIA_SEMANA'].value_counts()\n",
    "\n",
    "# Calcular m√©dia de crimes por dia da semana\n",
    "media_normal = (crimes_normal / contagem_dias_normal).fillna(0)\n",
    "media_futebol = (crimes_futebol / contagem_dias_futebol).fillna(0)\n",
    "\n",
    "# Juntar os dois em um DataFrame\n",
    "comparativo = pd.DataFrame({\n",
    "    'Dias Normais': media_normal,\n",
    "    'Dias com Jogos': media_futebol\n",
    "}).fillna(0)\n",
    "\n",
    "# Ordenar os dias da semana corretamente\n",
    "ordem_dias = [\n",
    "    'SEGUNDA-FEIRA', 'TER√áA-FEIRA', 'QUARTA-FEIRA',\n",
    "    'QUINTA-FEIRA', 'SEXTA-FEIRA', 'S√ÅBADO', 'DOMINGO'\n",
    "]\n",
    "comparativo = comparativo.reindex(ordem_dias)\n",
    "\n",
    "# Plotar gr√°fico de barras lado a lado\n",
    "plt.figure(figsize=(12, 6))\n",
    "comparativo.plot(kind='bar', width=0.8, color=['#808080', '#1E90FF'], edgecolor='black')\n",
    "\n",
    "plt.title('M√©dia de Crimes por Dia da Semana\\nCompara√ß√£o: Dias Normais vs Dias com Jogos de Futebol', fontsize=14, pad=20)\n",
    "plt.xlabel('Dia da Semana', fontsize=12)\n",
    "plt.ylabel('M√©dia de Crimes por Dia', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como √© poss√≠vel ver no gr√°fico, as m√©dias de crimes em dias com jogos marcados s√£o, em alguns casos, maiores do que as m√©dias em dias comuns, para todos os dias da semana. Mas, apesar de a interfer√™ncia do fator 'partida de futebol' j√° estar bastante evidente, analisaremos tamb√©m estatisticamente usando o m√©todo de hip√≥teses.\n",
    "\n",
    "### Teste de Hip√≥tese: Impacto de Jogos de Futebol na M√©dia de Crimes\n",
    "\n",
    "Neste teste, buscamos avaliar se h√° uma diferen√ßa estatisticamente significativa na **m√©dia de crimes registrados em dias com jogos de futebol** em compara√ß√£o com **dias normais**, em S√£o Paulo no ano de 2022.\n",
    "\n",
    "### Hip√≥teses\n",
    "\n",
    "- H‚ÇÄ (hip√≥tese nula): A m√©dia de crimes em dias com jogos √© igual √† m√©dia de dias normais.\n",
    "- H‚ÇÅ (hip√≥tese alternativa): A m√©dia de crimes em dias com jogos √© **maior** do que a m√©dia de dias normais.\n",
    "\n",
    "\n",
    "Utilizamos um **teste de hip√≥tese para diferen√ßa de m√©dias** com base na distribui√ß√£o normal (z-teste), assumindo:\n",
    "- Os dados seguem uma distribui√ß√£o aproximadamente normal (via Teorema Central do Limite).\n",
    "- As amostras s√£o independentes.\n",
    "\n",
    "O valor de **z-score** √© calculado pela f√≥rmula:\n",
    "\n",
    "$$\n",
    "z = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "- \\( $\\bar{x}_1$, $s_1$, $n_1$ \\) s√£o m√©dia, desvio padr√£o e tamanho da amostra dos **dias com jogos**\n",
    "- \\( $\\bar{x}_2$, $s_2$, $n_2$ \\) s√£o os mesmos para **dias normais**\n",
    "\n",
    "Em seguida, comparamos o **valor-p** ao n√≠vel de signific√¢ncia usual de 5% \\( $\\alpha$ = 0.05 \\). Se o valor-p for menor que 0.05, rejeitamos a hip√≥tese nula.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# Agrupar total de crimes por dia\n",
    "crimes_por_dia = df.groupby(['DATA_OCORRENCIA', 'CATEGORIA_EVENTO']).size().reset_index(name='TOTAL_CRIMES')\n",
    "\n",
    "# Separar amostras\n",
    "crimes_normais = crimes_por_dia[crimes_por_dia['CATEGORIA_EVENTO'] == 'DIA NORMAL']['TOTAL_CRIMES']\n",
    "crimes_jogos = crimes_por_dia[crimes_por_dia['CATEGORIA_EVENTO'] == 'JOGOS FUTEBOL']['TOTAL_CRIMES']\n",
    "\n",
    "# Par√¢metros das amostras\n",
    "x1 = crimes_jogos.mean()\n",
    "x2 = crimes_normais.mean()\n",
    "s1 = crimes_jogos.std(ddof=1)\n",
    "s2 = crimes_normais.std(ddof=1)\n",
    "n1 = len(crimes_jogos)\n",
    "n2 = len(crimes_normais)\n",
    "\n",
    "# Estat√≠stica z\n",
    "z = (x1 - x2) / np.sqrt((s1**2)/n1 + (s2**2)/n2)\n",
    "\n",
    "# Valor-p (teste unilateral √† direita)\n",
    "p_valor = 1 - norm.cdf(z)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"M√©dia (jogos): {x1:.2f}\")\n",
    "print(f\"M√©dia (normais): {x2:.2f}\")\n",
    "print(f\"Z-score: {z:.2f}\")\n",
    "print(f\"Valor-p: {p_valor:.4f}\")\n",
    "\n",
    "# Conclus√£o\n",
    "alpha = 0.05\n",
    "if p_valor < alpha:\n",
    "    print(\"‚û°Ô∏è Rejeitamos H‚ÇÄ: H√° evid√™ncia de que a m√©dia de crimes em dias com jogos √© maior.\")\n",
    "else:\n",
    "    print(\"‚û°Ô∏è N√£o rejeitamos H‚ÇÄ: N√£o h√° evid√™ncia suficiente de que a m√©dia seja maior.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme vimos acima, o teste de hip√≥tese est√° em concord√¢ncia com os gr√°ficos apresentados anteriormente. Portanto, com o resultado obtido, **√© poss√≠vel afirmar que a ocorr√™ncia de uma partida de futebol em determinada data pode repercutir em um not√°vel aumento no n√∫mero de crimes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <h2>O crime folga aos fins de semana: infer√™ncia estat√≠stica</h2>\n",
    "  An√°lise por Arthur Teodoro\n",
    "  <p>Ficou provado que os n√∫meros de crimes aumentam dependendo se h√° ou n√£o partidas de futebol na data, mas h√° diferen√ßa com rela√ß√£o ao dia da semana em que esses jogos ocorrem? Jogos no meio da semana tem ainda mais crimes que os jogos de s√°bado e domingo? A seguir an√°lisaremos, novamente, de forma gr√°fica e estat√≠stica, se h√° uma correla√ß√£o\n",
    "  Observe o gr√°fico a seguir:</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garantir datetime\n",
    "df['DATA_OCORRENCIA'] = pd.to_datetime(df['DATA_OCORRENCIA'], errors='coerce')\n",
    "\n",
    "# Criar coluna com dia da semana em portugu√™s\n",
    "dias_semana = {\n",
    "    'Monday': 'SEGUNDA-FEIRA', 'Tuesday': 'TER√áA-FEIRA', 'Wednesday': 'QUARTA-FEIRA',\n",
    "    'Thursday': 'QUINTA-FEIRA', 'Friday': 'SEXTA-FEIRA', 'Saturday': 'S√ÅBADO', 'Sunday': 'DOMINGO'\n",
    "}\n",
    "df['DIA_SEMANA'] = df['DATA_OCORRENCIA'].dt.day_name().map(dias_semana)\n",
    "\n",
    "# Adicionar classifica√ß√£o \"FIM DE SEMANA\" ou \"DIA √öTIL\"\n",
    "df['TIPO_DIA'] = df['DIA_SEMANA'].apply(lambda x: 'FIM DE SEMANA' if x in ['S√ÅBADO', 'DOMINGO'] else 'DIA √öTIL')\n",
    "\n",
    "# Filtrar apenas os dias com jogos\n",
    "df_jogos = df[df['CATEGORIA_EVENTO'] == 'JOGOS FUTEBOL']\n",
    "\n",
    "# Agrupar por data para obter n√∫mero de crimes por dia\n",
    "crimes_por_dia_jogo = df_jogos.groupby(['DATA_OCORRENCIA', 'TIPO_DIA']).size().reset_index(name='QTD_CRIMES')\n",
    "\n",
    "# Calcular m√©dia por tipo de dia\n",
    "media_crimes = crimes_por_dia_jogo.groupby('TIPO_DIA')['QTD_CRIMES'].mean().reset_index()\n",
    "\n",
    "# Plotar\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=media_crimes, x='TIPO_DIA', y='QTD_CRIMES', palette=['#1E90FF', '#FF8C00'])\n",
    "\n",
    "# Adicionar r√≥tulos\n",
    "for i, row in media_crimes.iterrows():\n",
    "    plt.text(i, row['QTD_CRIMES'] + 1, f'{row[\"QTD_CRIMES\"]:.1f}', ha='center', fontsize=11)\n",
    "\n",
    "plt.title('M√©dia de Crimes em Dias com Jogos de Futebol\\nComparando Fins de Semana e Dias √öteis', fontsize=14, pad=20)\n",
    "plt.xlabel('Tipo de Dia', fontsize=12)\n",
    "plt.ylabel('M√©dia de Crimes por Dia com Jogo', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando apenas s√°bado e domingo como fim de semana, e os demais dias como meio de semana, n√£o √© poss√≠vel observar claramente uma grande diferen√ßa entre as m√©dias representadas nas barras. Portanto, realizaremos novamente um teste de hip√≥tese para verificar se h√° uma diferen√ßa significativa entre o fim de semana e o meio de semana.\n",
    "\n",
    "### Hip√≥teses:\n",
    "\n",
    "- **H‚ÇÄ (nula):** $\\mu_{\\text{√∫til}} = \\mu_{\\text{fim\\_semana}}$ (mesma m√©dia de crimes)\n",
    "- **H‚ÇÅ (alternativa):** $\\mu_{\\text{√∫til}} \\neq \\mu_{\\text{fim\\_semana}}$ (diferen√ßa significativa)\n",
    "\n",
    "Em seguida, comparamos o **valor-p** ao n√≠vel de signific√¢ncia usual de 5% \\( $\\alpha$ = 0.05 \\). Se o valor-p for menor que 0.05, rejeitamos a hip√≥tese nula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reutilizando os dados de dias com jogos\n",
    "df_jogos = df[df['CATEGORIA_EVENTO'] == 'JOGOS FUTEBOL']\n",
    "\n",
    "# Criar coluna com tipo de dia\n",
    "df_jogos['TIPO_DIA'] = df_jogos['DIA_SEMANA'].apply(lambda x: 'FIM DE SEMANA' if x in ['S√ÅBADO', 'DOMINGO'] else 'DIA √öTIL')\n",
    "\n",
    "# Agrupar por data e tipo de dia\n",
    "crimes_por_dia = df_jogos.groupby(['DATA_OCORRENCIA', 'TIPO_DIA']).size().reset_index(name='QTD_CRIMES')\n",
    "\n",
    "# Separar os dois grupos\n",
    "grupo_util = crimes_por_dia[crimes_por_dia['TIPO_DIA'] == 'DIA √öTIL']['QTD_CRIMES']\n",
    "grupo_fds = crimes_por_dia[crimes_por_dia['TIPO_DIA'] == 'FIM DE SEMANA']['QTD_CRIMES']\n",
    "\n",
    "# Estat√≠sticas b√°sicas\n",
    "media_util = grupo_util.mean()\n",
    "media_fds = grupo_fds.mean()\n",
    "std_util = grupo_util.std(ddof=1)\n",
    "std_fds = grupo_fds.std(ddof=1)\n",
    "n_util = len(grupo_util)\n",
    "n_fds = len(grupo_fds)\n",
    "\n",
    "# Estat√≠stica z\n",
    "z = (media_util - media_fds) / np.sqrt((std_util**2 / n_util) + (std_fds**2 / n_fds))\n",
    "\n",
    "# Valor-p (teste bilateral)\n",
    "p_valor = 2 * (1 - norm.cdf(abs(z)))\n",
    "\n",
    "# Exibir resultados\n",
    "print(f\"M√©dia (dia √∫til): {media_util:.2f}\")\n",
    "print(f\"M√©dia (fim de semana): {media_fds:.2f}\")\n",
    "print(f\"Z-score: {z:.2f}\")\n",
    "print(f\"Valor-p: {p_valor:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desta vez, o valor-p √© maior que 0,05, ou seja, n√£o rejeitamos a hip√≥tese nula (H‚ÇÄ).\n",
    "Ap√≥s a an√°lise do teste de hip√≥tese, conclu√≠mos que n√£o h√° uma diferen√ßa significativa no n√∫mero de crimes entre os dias de fim de semana e de meio de semana, e **n√£o √© poss√≠vel afirmar que um per√≠odo tende a apresentar mais ocorr√™ncias do que o outro**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <h2>Associa√ß√µes</h2>\n",
    "  <p>Abaixo exploraremos algumas associa√ß√µes para que possamos interpretar melhor os dados, e encontrar alguns padr√µes que posso ajudar a entend√™-los </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pensando em regras de associa√ß√£o, ir√° ser feita uma an√°lise de que turno do dia um crime √© realizado em um determinado, com base na natureza apurada, turno e local. (Matheus Kauan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a porcentagem de valores n√£o nulos\n",
    "porcentagem_nao_nulos = df['NATUREZA_APURADA'].notna().mean() * 100\n",
    "\n",
    "# Exibe a porcentagem\n",
    "print(f\"{porcentagem_nao_nulos:.2f}% dos dados de NATUREZA_APURADA n√£o s√£o nulos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a porcentagem de valores n√£o nulos\n",
    "porcentagem_nao_nulos = df['TIPO_LOCAL'].notna().mean() * 100\n",
    "\n",
    "# Exibe a porcentagem\n",
    "print(f\"{porcentagem_nao_nulos:.2f}% dos dados de TIPO_LOCAL n√£o s√£o nulos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a porcentagem de valores n√£o nulos\n",
    "porcentagem_nao_nulos = df['PERIODO_OCORRENCIA'].notna().mean() * 100\n",
    "\n",
    "# Exibe a porcentagem\n",
    "print(f\"{porcentagem_nao_nulos:.2f}% dos dados de PERIODO_OCORRENCIA n√£o s√£o nulos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ap√≥s as verifica√ß√µes, podemos realizar as an√°lises visto que maior parte dos dados possuem todos os atributos necess√°rios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona e faz uma c√≥pia expl√≠cita das colunas\n",
    "df_assoc = df[['NATUREZA_APURADA', 'TIPO_LOCAL', 'PERIODO_OCORRENCIA']].copy()\n",
    "\n",
    "# Agora √© seguro remover os nulos sem warnings\n",
    "df_assoc.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala automaticamente o mlxtend, se n√£o estiver instalado\n",
    "try:\n",
    "    from mlxtend.preprocessing import TransactionEncoder\n",
    "    from mlxtend.frequent_patterns import apriori, association_rules\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"mlxtend\"])\n",
    "    from mlxtend.preprocessing import TransactionEncoder\n",
    "    from mlxtend.frequent_patterns import apriori, association_rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assoc['itens'] = df_assoc.apply(lambda row: [\n",
    "    f\"NATUREZA={row['NATUREZA_APURADA']}\",\n",
    "    f\"LOCAL={row['TIPO_LOCAL']}\",\n",
    "    f\"PERIODO={row['PERIODO_OCORRENCIA']}\"\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(df_assoc['itens']).transform(df_assoc['itens'])\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera itemsets frequentes com suporte m√≠nimo de 1%\n",
    "freq_items = apriori(df_encoded, min_support=0.01, use_colnames=True)\n",
    "\n",
    "# Gera regras com confian√ßa m√≠nima de 60%\n",
    "regras = association_rules(freq_items, metric=\"confidence\")\n",
    "\n",
    "# Exibe as 10 primeiras\n",
    "regras[['antecedents', 'consequents', 'support', 'confidence', 'lift']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regras.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arquivo CSV atualizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('dados/SpSafe_2022(c_cidades).csv', delimiter=';')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Agora tentaramos ver se √© valido o investimento em efetivo policial nas sextas e s√°bados a noite a fim de uma melhor preven√ß√£o ao crime (Gabriel) </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a porcentagem de valores n√£o nulos\n",
    "porcentagem_nao_nulos = df['DIA_SEMANA'].notna().mean() * 100\n",
    "\n",
    "print(f\"{porcentagem_nao_nulos:.2f}% dos dados de DIA_SEMANA n√£o s√£o nulos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Como 99,91% dos dados DIA_SEMANA n√£o s√£o nulos, irei descartar os que s√£o, e construir a tabela de transa√ß√£o com os disponiveis </p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte para mai√∫sculas (caso os dados estejam com letras min√∫sculas ou misturadas)\n",
    "df['DIA_SEMANA'] = df['DIA_SEMANA'].str.upper()\n",
    "df['PERIODO_OCORRENCIA'] = df['PERIODO_OCORRENCIA'].str.upper()\n",
    "\n",
    "# Filtra os dados com base nos crit√©rios\n",
    "df_filtrado = df.dropna(subset=['DIA_SEMANA', 'PERIODO_OCORRENCIA', 'NATUREZA_APURADA'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Usando o algoritmo apriori para validar (ou n√£o) as associa√ßoes </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo um filtro com as colunas envolvidas \n",
    "transacoes = df_filtrado.apply(lambda row: [\n",
    "    f\"DIA_SEMANA={row['DIA_SEMANA']}\",\n",
    "    f\"PERIODO_OCORRENCIA={row['PERIODO_OCORRENCIA']}\",\n",
    "    f\"NATUREZA_APURADA={row['NATUREZA_APURADA']}\"\n",
    "], axis=1).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# 1. Montar as transa√ß√µes apenas com DIA_SEMANA e PERIODO_OCORRENCIA\n",
    "transacoes_temporais = df_filtrado.apply(lambda row: [\n",
    "    f\"DIA_SEMANA={row['DIA_SEMANA']}\",\n",
    "    f\"PERIODO_OCORRENCIA={row['PERIODO_OCORRENCIA']}\"\n",
    "], axis=1).tolist()\n",
    "\n",
    "# 2. Codificar as transa√ß√µes\n",
    "te_temp = TransactionEncoder()\n",
    "te_temp_ary = te_temp.fit(transacoes_temporais).transform(transacoes_temporais)\n",
    "df_encoded_temp = pd.DataFrame(te_temp_ary, columns=te_temp.columns_)\n",
    "\n",
    "# 3. Rodar Apriori\n",
    "frequent_itemsets_temp = apriori(df_encoded_temp, min_support=0.01, use_colnames=True)\n",
    "\n",
    "# 4. Gerar regras de associa√ß√£o\n",
    "regras_temp = association_rules(frequent_itemsets_temp, metric=\"confidence\", min_threshold=0.1)\n",
    "\n",
    "# 5. Deixar os resultados mais leg√≠veis\n",
    "regras_temp['antecedents'] = regras_temp['antecedents'].apply(lambda x: ', '.join(list(x)))\n",
    "regras_temp['consequents'] = regras_temp['consequents'].apply(lambda x: ', '.join(list(x)))\n",
    "\n",
    "# 6. Selecionar e ordenar\n",
    "regras_temporais_formatadas = regras_temp[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
    "regras_ordenadas = regras_temporais_formatadas.sort_values(by='lift', ascending=False)\n",
    "\n",
    "# 7. Mostrar as top regras\n",
    "print(regras_ordenadas.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Com a execu√ß√£o do algoritmo temos: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar regras onde antecedents √© 'DIA_SEMANA=SEXTA-FEIRA' e consequents √© 'PERIODO_OCORRENCIA=A NOITE'\n",
    "filtro = (\n",
    "    ((regras_ordenadas['antecedents'] == 'DIA_SEMANA=SEXTA-FEIRA') |\n",
    "     (regras_ordenadas['antecedents'] == 'DIA_SEMANA=S√ÅBADO')) &\n",
    "    (regras_ordenadas['consequents'] == 'PERIODO_OCORRENCIA=A NOITE')\n",
    ")\n",
    "regras_ordenadas[filtro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordena as regras pelo suporte de forma decrescente\n",
    "regras_ordenadas = regras_ordenadas.sort_values(by='support', ascending=False)\n",
    "regras_ordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_support = regras_ordenadas['support'].mean()\n",
    "print(f\"M√©dia do suporte: {media_support:.4f}\")\n",
    "mediana_support = regras_ordenadas['support'].median()\n",
    "print(f\"Mediana do suporte: {mediana_support:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Analisando os dados, vi que aproximadamente associando sexta-feira e s√°bado com o total, 5% de todas as ocorr√™ncia ocorreram em cada  um desses dias. e Desse sub-conjunto, aproximadamente 30% ocorreram a noite, com o lift beirando a estabilidade. Vendo o conjunto de dados por completo, percebi que que a distribui√ß√£o dos crimes pelo dia da semana est√° bem normalizada, tendo a m√©dia e a mediana aproximadamente com 3%. Sendo assim, n√£o valeria a pena o investimento em efetivo policial em determinado dia da semana e periodo como forma preven√ß√£o a crime.</p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <h3>Tipos de crimes para com locais de elabora√ß√£o</h3>\n",
    "  <p>Estudo para descobrir se h√° associa√ß√£o entre o tipo de vrime que a pessoa passou para com o tipo de delegacia que foi elaborado o B.O</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando se h√° algum ru√≠do nos campos que ser√£o utilizados para realizar o estudo de associatividade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentagem_crimes = df['NATUREZA_APURADA'].notna().mean() * 100\n",
    "print(f\"{porcentagem_crimes:.2f}% das linhas possuem 'NATUREZA_APURADA' preenchida.\")\n",
    "\n",
    "porcentagem_elab = df['LOCAL_ELABORACAO'].notna().mean() * 100\n",
    "print(f\"{porcentagem_elab:.2f}% das linhas possuem 'LOCAL_ELABORACAO' preenchida.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria√ß√£o de grupos de tipos de delegacias e tipos de crimes semelhantes(podendo pertencer a algum grupo). Foi feito isso na inten√ß√£o de diminuir a quantidade de itens e itensets poss√≠veis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grupo_delegacia = {\n",
    "    \"Delegacia Distrital (DP)\": r\"\\d+¬∫ D\\.P\\.\",\n",
    "    \"Delegacia de Plant√£o\": r\"PLANTAO|PLANT√ÉO\",\n",
    "    \"Delegacia da Mulher (DDM)\": r\"DDM\",\n",
    "    \"Delegacia de Homic√≠dios (DHPP/DIG)\": r\"DHPP|DIG|HOMICIDIOS\",\n",
    "    \"Delegacia de Narc√≥ticos (DISE/DENARC)\": r\"DISE|DENARC|ENTORPECENTES\",\n",
    "    \"Delegacia de Roubos (DRADE)\": r\"DRADE|ROUBO|FURTO\",\n",
    "    \"Delegacia de Crimes Financeiros (DCCIBER)\": r\"DCCIBER|FRAUDE|FINANCEIRO\",\n",
    "    \"Delegacia do Idoso\": r\"PROTECAO IDOSO|IDOSO\",\n",
    "    \"Delegacia da Crian√ßa/Adolescente\": r\"INF\\.JUV|JUVENIL|CRIAN√áA\",\n",
    "    \"Delegacia de Capturas (DIPE)\": r\"DIPE|CAPTURA|FUGA\",\n",
    "    \"Delegacia Ambiental (DICCA)\": r\"DICCA|AMBIENTAL\",\n",
    "    \"Delegacia da Fazenda (DIIMA)\": r\"DIIMA|FAZENDA|SONEGA√á√ÉO\",\n",
    "    \"Delegacia Municipal (DEL.POL.)\": r\"^DEL\\.POL\\.\",\n",
    "    \"Delegacia Eletr√¥nica\": r\"ELETRONICA|ONLINE\",\n",
    "    \"Circunscri√ß√£o Policial (CPJ)\": r\"CPJ\",\n",
    "    \"Outras\": r\".*\"  # Padr√£o gen√©rico (caso n√£o se encaixe em nenhum outro)\n",
    "}\n",
    "\n",
    "def classificar_delegacia(delegacia):\n",
    "    for grupo, regex in grupo_delegacia.items():\n",
    "        if re.search(regex, delegacia, re.IGNORECASE):\n",
    "            return grupo\n",
    "    return \"Outras\"  # Caso n√£o encontre nenhum padr√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "grupos_crime = {\n",
    "    # 1. Crimes Violentos Contra a Vida\n",
    "    \"Homic√≠dio Doloso\": r\"HOMICIDIO DOLOSO|HOMICIDIO SIMPLES|HOMICIDIO QUALIFICADO\",\n",
    "    \"Morte Decorrente de Interven√ß√£o Policial\": r\"MORTE DECORRENTE DE INTERVENCAO POLICIAL\",\n",
    "    \"Les√£o Corporal Seguida de Morte\": r\"LESAO CORPORAL SEGUIDA DE MORTE\",\n",
    "    \"Latroc√≠nio\": r\"LATROCINIO\",\n",
    "    \n",
    "    # 2. Roubos (subdivididos)\n",
    "    \"Roubo a Pessoa\": r\"ROUBO.*TRANSEUNTE|ROUBO.*SAIDINHA\",\n",
    "    \"Roubo a Ve√≠culos\": r\"ROUBO.*VEICULO|ROUBO.*CARGA\",\n",
    "    \"Roubo a Estabelecimentos\": r\"ROUBO.*ESTABELECIMENTO|ROUBO.*JOALHERIA\",\n",
    "    \"Roubo em Resid√™ncias\": r\"ROUBO.*RESIDENCIA|ROUBO.*CONDOMINIO\",\n",
    "    \n",
    "    # 3. Furtos (subdivididos)\n",
    "    \"Furto a Ve√≠culos\": r\"FURTO.*VEICULO|FURTO.*INTERIOR DE VEICULO\",\n",
    "    \"Furto a Estabelecimentos\": r\"FURTO.*ESTABELECIMENTO|FURTO.*JOALHERIA\",\n",
    "    \"Furto em Resid√™ncias\": r\"FURTO.*RESIDENCIA|FURTO.*CONDOMINIO\",\n",
    "    \"Furto Qualificado\": r\"FURTO QUALIFICADO\",\n",
    "    \n",
    "    # 4. Crimes Sexuais\n",
    "    \"Estupro\": r\"ESTUPRO|ART\\. 213\",\n",
    "    \"Importuna√ß√£o Sexual\": r\"IMPORTUNACAO SEXUAL|ASSEDIO SEXUAL\",\n",
    "    \"Crimes Sexuais contra Vulner√°veis\": r\"ESTUPRO DE VULNERAVEL|CORRUPCAO DE MENORES\",\n",
    "    \n",
    "    # 5. Crimes contra o Patrim√¥nio (outros)\n",
    "    \"Extors√£o\": r\"EXTORSAO\",\n",
    "    \"Fraudes\": r\"ESTELIONATO|FRAUDE|MOEDA FALSA\",\n",
    "    \"Dano\": r\"DANO|DANO QUALIFICADO\",\n",
    "    \n",
    "    # 6. Crimes contra a Pessoa\n",
    "    \"Les√£o Corporal\": r\"LESAO CORPORAL\",\n",
    "    \"Amea√ßa\": r\"AMEACA|PERSEGUIR\",\n",
    "    \"Viol√™ncia Dom√©stica\": r\"VIOLENCIA DOMESTICA|VIOLENCIA PSICOLOGICA\",\n",
    "    \n",
    "    # 7. Crimes de Tr√¢nsito\n",
    "    \"Embriaguez ao Volante\": r\"EMBRIAGUEZ AO VOLANTE\",\n",
    "    \"Acidentes de Tr√¢nsito\": r\"ACIDENTE|ATROPELAMENTO|COLISAO\",\n",
    "    \"Dire√ß√£o Perigosa\": r\"DIRECAO PERIGOSA|VELOCIDADE INCOMPATIVEL\",\n",
    "    \n",
    "    # 8. Crimes contra a Administra√ß√£o P√∫blica\n",
    "    \"Corrup√ß√£o\": r\"CORRUPCAO\",\n",
    "    \"Falsifica√ß√£o\": r\"FALSIDADE|FALSIFICACAO\",\n",
    "    \n",
    "    # 9. Crimes Digitais\n",
    "    \"Crimes Cibern√©ticos\": r\"INFORMATICA|INVASAO DE DISPOSITIVO\",\n",
    "    \n",
    "    # 10. Outros Crimes\n",
    "    \"Porte Ilegal de Arma\": r\"PORTE ILEGAL|POSSE ILEGAL DE ARMA\",\n",
    "    \"Tr√°fico de Drogas\": r\"DROGAS.*AUTORIZACAO|ENTORPECENTES\",\n",
    "    \"Outros Crimes\": r\".*\"  # Padr√£o gen√©rico para casos n√£o classificados\n",
    "}\n",
    "\n",
    "def classificar_crime(crime):\n",
    "    for grupo, regex in grupos_crime.items():\n",
    "        if re.search(regex, crime, re.IGNORECASE):\n",
    "            return grupo\n",
    "    return \"Outros Crimes\"  # Caso n√£o encontre nenhum padr√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "df['GRUPO_ELAB'] = df['LOCAL_ELABORACAO'].apply(classificar_delegacia)\n",
    "df['GRUPO_CRIME'] = df['NATUREZA_APURADA'].apply(classificar_crime)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elab_group = df[['NUM_BO','GRUPO_CRIME', 'GRUPO_ELAB']].copy()\n",
    "df_elab_group.dropna(inplace=True)\n",
    "df_elab_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elab = df[['NUM_BO','NATUREZA_APURADA','LOCAL_ELABORACAO']].copy()\n",
    "df_elab.dropna(inplace=True)\n",
    "df_elab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elab_group['itens'] = df_elab_group.apply(lambda row: [row['GRUPO_CRIME'], row['GRUPO_ELAB']], axis=1)\n",
    "print(df_elab_group[['itens']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_elab['itens'] = df_elab.apply(lambda row: [row['NATUREZA_APURADA'], row['LOCAL_ELABORACAO']], axis=1)\n",
    "print(df_elab[['itens']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Inicializar e transformar os dados\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(df_elab['itens']).transform(df_elab['itens'])\n",
    "\n",
    "# Criar DataFrame codificado\n",
    "df_encoded_elab = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "df_encoded_elab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Inicializar e transformar os dados\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(df_elab_group['itens']).transform(df_elab_group['itens'])\n",
    "\n",
    "# Criar DataFrame codificado\n",
    "df_encoded_elab_group = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "df_encoded_elab_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "# Encontrar itens frequentes (pares crime + delegacia)\n",
    "frequent_itemsets = apriori(\n",
    "    df_encoded_elab,\n",
    "    min_support=0.05,  # Ajuste conforme seu dataset (ex: 5% das ocorr√™ncias)\n",
    "    use_colnames=True\n",
    ")\n",
    "\n",
    "# Ordenar por suporte\n",
    "frequent_itemsets = frequent_itemsets.sort_values(by='support', ascending=False)\n",
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "# Encontrar itens frequentes (pares crime + delegacia)\n",
    "frequent_itemsets = apriori(\n",
    "    df_encoded_elab_group,\n",
    "    min_support=0.05,  # Ajuste conforme seu dataset (ex: 5% das ocorr√™ncias)\n",
    "    use_colnames=True\n",
    ")\n",
    "\n",
    "# Ordenar por suporte\n",
    "frequent_itemsets_group = frequent_itemsets.sort_values(by='support', ascending=False)\n",
    "frequent_itemsets_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a finalidade de entender se h√° alguma rela√ß√£o entre crimes e locais de leabora√ß√£o a confian√ßa foi ajustada para zero, mesmo assim houve apenas poucos casos de associa√ß√£o(repetidos), mesmo juntando as duas abordagens(agrupada e n√£o agrupada). Embora exista o seu grau de confian√ßa √© muito baixo, al√©m de seu grau de associa√ß√£o tamb√©m ser baixo e o lift alto. *Necess√°rio uma busca para entender o que estes dados est√£o querendo dizer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# Gerar regras com base na confian√ßa ou lift\n",
    "rules = association_rules(\n",
    "    frequent_itemsets,\n",
    "    metric='confidence',\n",
    "    min_threshold=0.00  # Confian√ßa m√≠nima de 0%\n",
    ")\n",
    "\n",
    "# Filtrar regras relevantes (ex: lift > 1.5)\n",
    "rules[rules['lift'] >= 0.01].sort_values(by='lift', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# Gerar regras com base na confian√ßa ou lift\n",
    "rules = association_rules(\n",
    "    frequent_itemsets_group,\n",
    "    metric='confidence',\n",
    "    min_threshold=0.00  # Confian√ßa m√≠nima de 0%\n",
    ")\n",
    "\n",
    "# Filtrar regras relevantes (ex: lift > 1.5)\n",
    "rules[rules['lift'] >= 0.01].sort_values(by='lift', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Futebol (datas de jogos importantes de times paulistas em 2022)\n",
    "jogos_futebol = [\n",
    "    '2022-01-27',  # Athletico-PR 1-1 S√£o Paulo\n",
    "    '2022-02-20',  # Internacional 2-1 Corinthians\n",
    "    '2022-03-06',  # Flamengo 1-1 Palmeiras\n",
    "    '2022-04-02',  # S√£o Paulo 2-1 Palmeiras (Paulist√£o)\n",
    "    '2022-04-10',  # Corinthians 1-0 Flamengo\n",
    "    '2022-04-17',  # Atl√©tico-MG 0-0 Santos\n",
    "    '2022-05-15',  # Fluminense 2-0 Corinthians\n",
    "    '2022-05-22',  # S√£o Paulo 1-1 Palmeiras\n",
    "    '2022-06-19',  # Fortaleza 0-3 Palmeiras\n",
    "    '2022-07-10',  # Botafogo 1-2 S√£o Paulo\n",
    "    '2022-07-13',  # S√£o Paulo 3-1 Juventude (Copa do Brasil)\n",
    "    '2022-08-07',  # Goi√°s 1-0 Santos\n",
    "    '2022-08-13',  # Corinthians 0-2 Flamengo (Copa do Brasil)\n",
    "    '2022-08-28',  # Palmeiras 4-2 Corinthians\n",
    "    '2022-09-04',  # Coritiba 0-1 Palmeiras\n",
    "    '2022-09-17',  # Santos 0-1 S√£o Paulo\n",
    "    '2022-10-02',  # Cuiab√° 1-1 Corinthians\n",
    "    '2022-11-06',  # Ava√≠ 1-3 S√£o Paulo\n",
    "    '2022-11-24',  # Corinthians 2-0 S√£o Paulo\n",
    "    '2022-11-28',  # Corinthias 1-0 Athetico-PR\n",
    "    '2022-12-02',  # Am√©rica-MG 1-2 Palmeiras\n",
    "    '2022-12-05',  # S√£o Paulo 4-0 Fluminense\n",
    "    '2022-12-09'   # Santos 2-1 Botafogo\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionando o campo de 'Houve_JOGO' no dataset, para melhorar a manipula√ß√£o dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HOUVE_JOGO'] = df['DATA_OCORRENCIA'].dt.strftime('%Y-%m-%d').isin(jogos_futebol)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo apenas quais campos ser√£o utilizados para verificar sua assosiatividade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jogos = df[['NATUREZA_APURADA', 'HOUVE_JOGO']].copy()\n",
    "df_jogos.dropna(inplace=True)\n",
    "df_jogos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colocando no formato de transi√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jogos['itens'] = df_jogos.apply(lambda row: [row['NATUREZA_APURADA'], row['HOUVE_JOGO']], axis=1)\n",
    "print(df_jogos[['itens']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Criar transa√ß√µes no formato: [['ROUBO', 'SIM_JOGO'], ['FURTO', 'NAO_JOGO'], ...]\n",
    "transacoes = df_jogos.apply(\n",
    "    lambda row: [row['NATUREZA_APURADA'], 'SIM_JOGO' if row['HOUVE_JOGO'] else 'NAO_JOGO'], \n",
    "    axis=1\n",
    ").tolist()\n",
    "\n",
    "# Codificar como matriz bin√°ria\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit_transform(transacoes)\n",
    "df_encoded_jogos = pd.DataFrame(te_array, columns=te.columns_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando o algoritmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "# Itens frequentes (suporte m√≠nimo de 5%)\n",
    "frequent_items_jogos = apriori(df_encoded_jogos, min_support=0.05, use_colnames=True)\n",
    "frequent_items_jogos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# Regras com confian√ßa m√≠nima de 70%\n",
    "regras = association_rules(frequent_items_jogos, metric=\"confidence\", min_threshold=0.0001)\n",
    "regras[['antecedents', 'consequents', 'support', 'confidence', 'lift']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h3> Jogos de futebol com tipos de crimes </h3>\n",
    "    <p> Os jogos de futebol ser√£o usados aqueles que tiverem algum time paulista </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1> Arquivo csv atualizado </h1>\n",
    "    <p> Executar a c√©lula somente se n√£o tiver o arquivo .csv do SpSafe atualizado.  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenta importar gdown, se n√£o conseguir, instala\n",
    "try:\n",
    "    import gdown  # Tenta importar novamente ap√≥s a instala√ß√£o\n",
    "except ImportError:\n",
    "    print(\"üì• gdown n√£o encontrado. Instalando automaticamente...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"gdown\"])\n",
    "\n",
    "# Baixar o arquivo do Google Drive\n",
    "\n",
    "file_id = \"1Tf6-immhPLj23A0Lvai52j-WQpl6KjKt\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "output = \"dados/SpSafe_2022(c_cidades).csv\"\n",
    "\n",
    "gdown.download(url, output, quiet=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
