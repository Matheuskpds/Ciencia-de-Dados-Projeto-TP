{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 align=\"center\"> Baixar o arquivo csv, caso n√£o tenha baixado o arquivo via github:</H2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Tenta importar gdown, se n√£o conseguir, instala\n",
    "try:\n",
    "    import gdown\n",
    "except ImportError:\n",
    "    print(\"üì• gdown n√£o encontrado. Instalando automaticamente...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"gdown\"])\n",
    "    import gdown  # Tenta importar novamente ap√≥s a instala√ß√£o\n",
    "\n",
    "# Baixar o arquivo do Google Drive\n",
    "\n",
    "file_id = \"1VbB_fvowkgNoWcLADi1mEfFjWQI6nBjp\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "output = \"dados/SpSafe_2022.csv\"\n",
    "\n",
    "gdown.download(url, output, quiet=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  Leitura do arquivo\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('dados/SpSafe_2022.csv', delimiter=';')\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 align=\"center\"> C√≥digos criados para adicionar uma coluna com os atributos dia da semana. </H2>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P aling = \"center\">  </P>\n",
    "<p align=\"center\">\n",
    "  Executar somente quando um novo arquivo for baixado do Google Drive\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T02:44:53.743629Z",
     "start_time": "2025-03-29T02:44:53.684912Z"
    }
   },
   "outputs": [],
   "source": [
    "#Conventendo a coluna DATA_OCORRENCIA para datetime para ser reconhecido como data pelo pandas\n",
    "df['DATA_OCORRENCIA'] = pd.to_datetime(df['DATA_OCORRENCIA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria√ß√£o de coluna com o dia da semana\n",
    "df.insert(df.columns.get_loc('DATA_OCORRENCIA') + 1, 'DIA_SEMANA', df['DATA_OCORRENCIA'].dt.day_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T02:44:59.246077Z",
     "start_time": "2025-03-29T02:44:59.110796Z"
    }
   },
   "outputs": [],
   "source": [
    "#Convertendo os dias da semana para portugu√™s\n",
    "dias_semana = {\n",
    "    'Monday': 'SEGUNDA-FEIRA', 'Tuesday': 'TER√áA-FEIRA', 'Wednesday': 'QUARTA-FEIRA',\n",
    "    'Thursday': 'QUINTA-FEIRA', 'Friday': 'SEXTA-FEIRA', 'Saturday': 'S√ÅBADO', 'Sunday': 'DOMINGO'\n",
    "}\n",
    "df['DIA_SEMANA'] = df['DATA_OCORRENCIA'].dt.day_name().map(dias_semana)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 align=\"center\"> C√≥digos criados para verificar se a data teve um evento at√≠pico. </H2>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  Executar somente para o arquivo csv baixado via Google Drive\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir os eventos de S√£o Paulo em 2022\n",
    "eventos_sp_2022 = [\n",
    "    #Feriados em Sp 2022:\n",
    "    '2022-01-01',  # Confraterniza√ß√£o Universal\n",
    "    '2022-04-15',  # Paix√£o de Cristo\n",
    "    '2022-04-21',  # Tiradentes\n",
    "    '2022-05-01',  # Dia do Trabalho\n",
    "    '2022-09-07',  # Independ√™ncia do Brasil\n",
    "    '2022-10-12',  # Nossa Senhora Aparecida\n",
    "    '2022-11-02',  # Finados\n",
    "    '2022-11-15',  # Proclama√ß√£o da Rep√∫blica\n",
    "    '2022-12-25',  # Natal\n",
    "    '2022-07-09',  # Revolu√ß√£o Constitucionalista\n",
    "    '2022-02-28',  # Carnaval\n",
    "    '2022-03-01',  # Carnaval\n",
    "    '2022-06-16',  # Corpus Christi\n",
    "    '2022-10-28',  # Dia do Servidor P√∫blico\n",
    "    \n",
    "    #Facultativos:\n",
    "    '2022-03-02',  # Quarta-Feira de Cinzas\n",
    "    '2022-12-24',  # V√©spera de Natal\n",
    "    '2022-12-31',   # V√©spera de Ano Novo\n",
    "\n",
    "    '2022-01-25',  # Final da Copa S√£o Paulo de Futebol J√∫nior\n",
    "    '2022-03-10',  # Palmeiras x S√£o Paulo - Paulista\n",
    "    '2022-03-30',  # Final Paulista - Jogo 1\n",
    "    '2022-04-03',  # Final Paulista - Jogo 2\n",
    "    '2022-05-02',  # S√£o Paulo x Santos - Brasileir√£o\n",
    "    '2022-05-22',  # Corinthians x S√£o Paulo - Brasileir√£o\n",
    "    '2022-06-20',  # S√£o Paulo x Palmeiras - Brasileir√£o\n",
    "    '2022-08-21',  # Santos x S√£o Paulo - Brasileir√£o\n",
    "    '2022-09-11',  # S√£o Paulo x Corinthians - Brasileir√£o\n",
    "    '2022-10-16',  # Palmeiras x S√£o Paulo - Brasileir√£o\n",
    "    \n",
    "    # Jogos da Copa do Mundo 2022 (Sele√ß√£o Brasileira)\n",
    "    '2022-11-24',  # Brasil 2 x 0 S√©rvia\n",
    "    '2022-11-28',  # Brasil 1 x 0 Su√≠√ßa\n",
    "    '2022-12-02',  # Camar√µes 1 x 0 Brasil\n",
    "    '2022-12-05',  # Brasil 4 x 1 Coreia do Sul (Oitavas)\n",
    "    '2022-12-09'   # Brasil 1(2) x (4)1 Cro√°cia (Quartas)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conventendo a coluna DATA_OCORRENCIA para datetime para ser reconhecido como data pelo pandas\n",
    "df['DATA_OCORRENCIA'] = pd.to_datetime(df['DATA_OCORRENCIA'])\n",
    "\n",
    "# Converter para datetime para compara√ß√£o\n",
    "eventos_dates = pd.to_datetime(eventos_sp_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar nova coluna 'DIA ATIPICO' que indica se na data aconteceu um evento at√≠pico:\n",
    "df['DIA ATIPICO'] = df['DATA_OCORRENCIA'].isin(eventos_dates)\n",
    "\n",
    "#Converter para texto mais descritivo\n",
    "df['DIA ATIPICO'] = df['DIA ATIPICO'].map({True: 'SIM', False: 'N√ÉO'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head(20)\n",
    "\n",
    "# Filtrar o DataFrame para retornar apenas as linhas onde 'DIA ATIPICO' √© 'SIM'\n",
    "df_atipico = df[df['DIA ATIPICO'] == 'SIM']\n",
    "# Exibir o resultado\n",
    "df_atipico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">\n",
    "  C√≥digo criados para localizar as cidades dos dados via latitude e longitude\n",
    "</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biblioteca usada para localizar o nome da cidade via latitude e longitude\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocal = Nominatim(user_agent=\"tpDados\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  Convertendo o tipo da coluna cidade para objeto por quest√µes de compatibilidade com o geopy\n",
    "  \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CIDADE\"] = df[\"CIDADE\"].astype(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_geolocal = {}\n",
    "for indice, linha in df.iterrows():\n",
    "    if pd.isna(linha[\"LATITUDE\"]) and pd.isna(linha[\"LONGITUDE\"]):\n",
    "        continue\n",
    "    if pd.isna(linha[\"CIDADE\"]) and pd.notna(linha[\"LATITUDE\"]) and pd.notna(linha[\"LONGITUDE\"]):\n",
    "        lat_long = (linha[\"LATITUDE\"], linha[\"LONGITUDE\"])\n",
    "        if lat_long in cache_geolocal:\n",
    "            df.at[indice, \"CIDADE\"] = cache_geolocal[lat_long]\n",
    "        else:\n",
    "            try:\n",
    "                local = geolocal.reverse(f\"{lat_long[0]}, {lat_long[1]}\")\n",
    "                cidade = local.raw[\"address\"].get(\"city\") or local.raw[\"address\"].get(\"town\", np.nan)\n",
    "                df.at[indice, \"CIDADE\"] = cidade\n",
    "                cache_geolocal[lat_long] = cidade\n",
    "            except ValueError:\n",
    "                df.at[indice, \"CIDADE\"] = np.nan\n",
    "                \n",
    "df.to_csv('dados/SpSafe_2022.csv', index=False, sep=';', encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  Comando para salvar o DataFrame em um arquivo csv\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dados/SpSafe_2022.csv', index=False, sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#Salvar cache de local\n",
    "with open(\"cache_geolocal.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cache_geolocal, f)\n",
    "\n",
    "\n",
    "\n",
    "#Salvar indice\n",
    "with open(\"indice.pkl\", \"wb\") as l:\n",
    "    pickle.dump(indice, l)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de PERIODO_OCORRENCIA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando Objetos que 'PERIODO_OCORRENCIA' s√£o \"NaN\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nam = df[df['PERIODO_OCORRENCIA'].isna()]\n",
    "df_nam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando Objetos que 'PERIODO_OCORRENCIA' e 'HORA_OCORRENCIA' s√£o \"NaN\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = df['HORA_OCORRENCIA'].isna().astype(bool)\n",
    "mask2 = df['PERIODO_OCORRENCIA'].isna().astype(bool)\n",
    "df_nam = df[mask1 & mask2]  # or mask1 | mask2 for OR condition\n",
    "df_nam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtro de Tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Filtra linhas onde PERIODO_OCORRENCIA √© nulo (usando isna)\n",
    "df_nam = df[df['PERIODO_OCORRENCIA'].isna()].copy()\n",
    "\n",
    "# 2. Atualiza PERIODO_OCORRENCIA baseado em HORA_OCORRENCIA (formato \"HH:MM:SS\")\n",
    "def definir_periodo(hora_str):\n",
    "    if pd.isna(hora_str):\n",
    "        return \"EM HORA INCERTA\"\n",
    "    \n",
    "    try:\n",
    "        hora_part = hora_str.split(':')[0]\n",
    "        hora = int(hora_part)\n",
    "    except (ValueError, IndexError, AttributeError):\n",
    "        return \"EM HORA INCERTA\"\n",
    "    \n",
    "    if 0 <= hora < 5:\n",
    "        return \"DE MADRUGADA\"\n",
    "    elif 5 <= hora < 12:\n",
    "        return \"PELA MANH√É\"\n",
    "    elif 12 <= hora < 18:\n",
    "        return \"A TARDE\"\n",
    "    elif 18 <= hora <= 23:\n",
    "        return \"A NOITE\"\n",
    "    else:\n",
    "        return \"EM HORA INCERTA\"\n",
    "\n",
    "# Aplica a fun√ß√£o para atualizar os valores\n",
    "df_nam['PERIODO_OCORRENCIA'] = df_nam['HORA_OCORRENCIA'].apply(definir_periodo)\n",
    "\n",
    "# Verifica o resultado\n",
    "df_nam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atualiza o DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PERIODO_OCORRENCIA'] = np.where(\n",
    "    df['PERIODO_OCORRENCIA'].isna(),\n",
    "    df['HORA_OCORRENCIA'].apply(definir_periodo),\n",
    "    df['PERIODO_OCORRENCIA']\n",
    ")\n",
    "\n",
    "df[df['PERIODO_OCORRENCIA'].isna()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
